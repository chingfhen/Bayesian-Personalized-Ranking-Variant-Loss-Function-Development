{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae52581-ec51-4ee1-b691-9417934b6252",
   "metadata": {},
   "source": [
    "# ABOUT:\n",
    "- this notebook is a test run of SimpleX using RecBole API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffffdc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# run 0 - notes:\n",
    "- the actual interaction data in under .inter_feat attribute\n",
    "- it appears that the value of \"by\" hyperparameter is the number of negative samples per user. \n",
    "    - But why can't i change this value to other than 1?\n",
    "    - maybe i need to set \"by\" such that (1+by) is a divisible by the batch size? other its set back to 1?\n",
    "- for each positive item, the corresponding negative items are in the same batch\n",
    "- update: number of negative samples is controlled by \"neg_sampling\" param not \"train_neg_sample_args\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4f33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SimpleX\"\n",
    "dataset = 'ml-100k'\n",
    "config_file_list = ['default_config.yaml', 'main_config.yaml']\n",
    "config_dict = {\n",
    "    \"show_progress\": False,\n",
    "    \"log_wandb\":True,\n",
    "    \"eval_step\": 10,\n",
    "    \"epochs\": 50, \n",
    "    \"eval_args\": {\"split\": {\"RS\": [6,2,2]}},\n",
    "    \"valid_metric\":\"NDCG@20\",\n",
    "    \"metrics\":[\"Recall\",\"NDCG\"],\n",
    "    \"topk\":[10,20],\n",
    "    \n",
    "    \"embedding_size\":32,\n",
    "    \"margin\":0.8,\n",
    "    \"negative_weight\":100,\n",
    "    \"gamma\":0.5,\n",
    "    \"reg_weight\":0,\n",
    "    \"aggregator\":\"mean\",\n",
    "    \"history_len\":10,\n",
    "    \"neg_sampling\":{\"uniform\":100}\n",
    "}\n",
    "saved = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0544ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2fac50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08 Sep 13:56    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = C:\\Users\\tanch\\anaconda3\\envs\\fyp0\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\n",
      "checkpoint_dir = saved/\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = True\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = {'uniform': 100}\n",
      "eval_step = 10\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [6, 2, 2]}, 'order': 'RO', 'group_by': 'user', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'NDCG']\n",
      "topk = [10, 20]\n",
      "valid_metric = NDCG@20\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "worker = 0\n",
      "shuffle = True\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 100, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "project = simplex_ablation_study\n",
      "embedding_size = 32\n",
      "margin = 0.8\n",
      "negative_weight = 100\n",
      "gamma = 0.5\n",
      "reg_weight = 0\n",
      "aggregator = mean\n",
      "history_len = 10\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "08 Sep 13:56    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "08 Sep 13:56    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 100}]\n",
      "08 Sep 13:56    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [6, 2, 2]}, 'order': 'RO', 'group_by': 'user', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "recbole.quick_start\n",
    "########################\n",
    "\"\"\"\n",
    "import logging\n",
    "from logging import getLogger\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation, save_split_dataloaders, load_split_dataloaders\n",
    "from recbole.utils import init_logger, get_model, get_trainer, init_seed, set_color\n",
    "\n",
    "\n",
    "# def run_recbole(model=None, dataset=None, config_file_list=None, config_dict=None, saved=True):\n",
    "\n",
    "# configurations initialization\n",
    "config = Config(model=model, dataset=dataset, config_file_list=config_file_list, config_dict=config_dict)\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "logger.info(config)\n",
    "\n",
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# # model loading and initialization\n",
    "# init_seed(config['seed'], config['reproducibility'])\n",
    "# model = get_model(config['model'])(config, train_data.dataset).to(config['device'])\n",
    "# logger.info(model)\n",
    "\n",
    "# # trainer loading and initialization\n",
    "# trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "# # model training\n",
    "# best_valid_score, best_valid_result = trainer.fit(\n",
    "#     train_data, valid_data, saved=saved, show_progress=config['show_progress']\n",
    "# )\n",
    "\n",
    "# # model evaluation\n",
    "# test_result = trainer.evaluate(test_data, load_best_model=saved, show_progress=config['show_progress'])\n",
    "\n",
    "# logger.info(set_color('best valid ', 'yellow') + f': {best_valid_result}')\n",
    "# logger.info(set_color('test result', 'yellow') + f': {test_result}')\n",
    "\n",
    "# {\n",
    "#     'best_valid_score': best_valid_score,\n",
    "#     'valid_score_bigger': config['valid_metric_bigger'],\n",
    "#     'best_valid_result': best_valid_result,\n",
    "#     'test_result': test_result\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47fde6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mGeneral Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36mgpu_id\u001b[0m =\u001b[1;33m 0\u001b[0m\n",
       "\u001b[1;36muse_gpu\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\u001b[1;36mseed\u001b[0m =\u001b[1;33m 2020\u001b[0m\n",
       "\u001b[1;36mstate\u001b[0m =\u001b[1;33m INFO\u001b[0m\n",
       "\u001b[1;36mreproducibility\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\u001b[1;36mdata_path\u001b[0m =\u001b[1;33m C:\\Users\\tanch\\anaconda3\\envs\\fyp0\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\u001b[0m\n",
       "\u001b[1;36mcheckpoint_dir\u001b[0m =\u001b[1;33m saved/\u001b[0m\n",
       "\u001b[1;36mshow_progress\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36msave_dataset\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36mdataset_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36msave_dataloaders\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36mdataloaders_save_path\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mlog_wandb\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\n",
       "\u001b[1;35mTraining Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36mepochs\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
       "\u001b[1;36mtrain_batch_size\u001b[0m =\u001b[1;33m 2048\u001b[0m\n",
       "\u001b[1;36mlearner\u001b[0m =\u001b[1;33m adam\u001b[0m\n",
       "\u001b[1;36mlearning_rate\u001b[0m =\u001b[1;33m 0.001\u001b[0m\n",
       "\u001b[1;36mneg_sampling\u001b[0m =\u001b[1;33m {'uniform': 10}\u001b[0m\n",
       "\u001b[1;36meval_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
       "\u001b[1;36mstopping_step\u001b[0m =\u001b[1;33m 10\u001b[0m\n",
       "\u001b[1;36mclip_grad_norm\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mweight_decay\u001b[0m =\u001b[1;33m 0.0\u001b[0m\n",
       "\u001b[1;36mloss_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
       "\n",
       "\u001b[1;35mEvaluation Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36meval_args\u001b[0m =\u001b[1;33m {'split': {'RS': [6, 2, 2]}, 'order': 'RO', 'group_by': 'user', 'mode': 'full'}\u001b[0m\n",
       "\u001b[1;36mrepeatable\u001b[0m =\u001b[1;33m False\u001b[0m\n",
       "\u001b[1;36mmetrics\u001b[0m =\u001b[1;33m ['Recall', 'NDCG']\u001b[0m\n",
       "\u001b[1;36mtopk\u001b[0m =\u001b[1;33m [10, 20]\u001b[0m\n",
       "\u001b[1;36mvalid_metric\u001b[0m =\u001b[1;33m NDCG@20\u001b[0m\n",
       "\u001b[1;36mvalid_metric_bigger\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\u001b[1;36meval_batch_size\u001b[0m =\u001b[1;33m 4096\u001b[0m\n",
       "\u001b[1;36mmetric_decimal_place\u001b[0m =\u001b[1;33m 4\u001b[0m\n",
       "\n",
       "\u001b[1;35mDataset Hyper Parameters:\n",
       "\u001b[0m\u001b[1;36mfield_separator\u001b[0m =\u001b[1;33m \t\u001b[0m\n",
       "\u001b[1;36mseq_separator\u001b[0m =\u001b[1;33m  \u001b[0m\n",
       "\u001b[1;36mUSER_ID_FIELD\u001b[0m =\u001b[1;33m user_id\u001b[0m\n",
       "\u001b[1;36mITEM_ID_FIELD\u001b[0m =\u001b[1;33m item_id\u001b[0m\n",
       "\u001b[1;36mRATING_FIELD\u001b[0m =\u001b[1;33m rating\u001b[0m\n",
       "\u001b[1;36mTIME_FIELD\u001b[0m =\u001b[1;33m timestamp\u001b[0m\n",
       "\u001b[1;36mseq_len\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mLABEL_FIELD\u001b[0m =\u001b[1;33m label\u001b[0m\n",
       "\u001b[1;36mthreshold\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mNEG_PREFIX\u001b[0m =\u001b[1;33m neg_\u001b[0m\n",
       "\u001b[1;36mload_col\u001b[0m =\u001b[1;33m {'inter': ['user_id', 'item_id']}\u001b[0m\n",
       "\u001b[1;36munload_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36munused_col\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36madditional_feat_suffix\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mrm_dup_inter\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mval_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mfilter_inter_by_user_or_item\u001b[0m =\u001b[1;33m True\u001b[0m\n",
       "\u001b[1;36muser_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mitem_inter_num_interval\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_user_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_item_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_entity_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36malias_of_relation_id\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mpreload_weight\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mnormalize_field\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mnormalize_all\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\u001b[1;36mITEM_LIST_LENGTH_FIELD\u001b[0m =\u001b[1;33m item_length\u001b[0m\n",
       "\u001b[1;36mLIST_SUFFIX\u001b[0m =\u001b[1;33m _list\u001b[0m\n",
       "\u001b[1;36mMAX_ITEM_LIST_LENGTH\u001b[0m =\u001b[1;33m 50\u001b[0m\n",
       "\u001b[1;36mPOSITION_FIELD\u001b[0m =\u001b[1;33m position_id\u001b[0m\n",
       "\u001b[1;36mHEAD_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m head_id\u001b[0m\n",
       "\u001b[1;36mTAIL_ENTITY_ID_FIELD\u001b[0m =\u001b[1;33m tail_id\u001b[0m\n",
       "\u001b[1;36mRELATION_ID_FIELD\u001b[0m =\u001b[1;33m relation_id\u001b[0m\n",
       "\u001b[1;36mENTITY_ID_FIELD\u001b[0m =\u001b[1;33m entity_id\u001b[0m\n",
       "\u001b[1;36mbenchmark_filename\u001b[0m =\u001b[1;33m None\u001b[0m\n",
       "\n",
       "\u001b[1;35mOther Hyper Parameters: \n",
       "\u001b[0m\u001b[1;36mwandb_project\u001b[0m = \u001b[1;33mrecbole\u001b[0m\n",
       "\u001b[1;36mrequire_pow\u001b[0m = \u001b[1;33mFalse\u001b[0m\n",
       "\u001b[1;36mMODEL_TYPE\u001b[0m = \u001b[1;33mModelType.GENERAL\u001b[0m\n",
       "\u001b[1;36mworker\u001b[0m = \u001b[1;33m0\u001b[0m\n",
       "\u001b[1;36mshuffle\u001b[0m = \u001b[1;33mTrue\u001b[0m\n",
       "\u001b[1;36mtrain_neg_sample_args\u001b[0m = \u001b[1;33m{'strategy': 'by', 'by': 100, 'distribution': 'uniform', 'dynamic': 'none'}\u001b[0m\n",
       "\u001b[1;36mproject\u001b[0m = \u001b[1;33msimplex_ablation_study\u001b[0m\n",
       "\u001b[1;36membedding_size\u001b[0m = \u001b[1;33m32\u001b[0m\n",
       "\u001b[1;36mmargin\u001b[0m = \u001b[1;33m0.8\u001b[0m\n",
       "\u001b[1;36mnegative_weight\u001b[0m = \u001b[1;33m100\u001b[0m\n",
       "\u001b[1;36mgamma\u001b[0m = \u001b[1;33m0.5\u001b[0m\n",
       "\u001b[1;36mreg_weight\u001b[0m = \u001b[1;33m0\u001b[0m\n",
       "\u001b[1;36maggregator\u001b[0m = \u001b[1;33mmean\u001b[0m\n",
       "\u001b[1;36mhistory_len\u001b[0m = \u001b[1;33m10\u001b[0m\n",
       "\u001b[1;36mMODEL_INPUT_TYPE\u001b[0m = \u001b[1;33mInputType.PAIRWISE\u001b[0m\n",
       "\u001b[1;36meval_type\u001b[0m = \u001b[1;33mEvaluatorType.RANKING\u001b[0m\n",
       "\u001b[1;36mdevice\u001b[0m = \u001b[1;33mcuda\u001b[0m\n",
       "\u001b[1;36meval_neg_sample_args\u001b[0m = \u001b[1;33m{'strategy': 'full', 'distribution': 'uniform'}\u001b[0m\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b3d3f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'item_id'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iid_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e236ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 584,  668,  299,  ...,  721,  205, 1256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.inter_feat[train_data.iid_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "681e389d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The batch_size of interaction: 10\n",
       "    user_id, torch.Size([10]), cpu, torch.int64\n",
       "    item_id, torch.Size([10]), cpu, torch.int64\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123348e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# run 1\n",
    "- run simplx, confirmed the following params to control: \n",
    "    - embedding_size: length of vector representing each user and item\n",
    "    - margin: threshold to discrimate hard negative samples (in CCL)\n",
    "    - negative_weight: balances effect of postive and negative samples on loss (CCL)\n",
    "    - gamma: balances user and their history of interactions for the final user embedding\n",
    "    - aggregator: aggregator for user's item history\n",
    "    - history_len: number of positive interactions to use per user\n",
    "    - neg_sampling: controls number of negative samples per user\n",
    "    - reg_weight: regularize all weights\n",
    "- it worked!\n",
    "    - SimpleX indeed reaches convergence very fast as mentioned in the paper\n",
    "    - SimpleX appears to be quite sensitive to hyperparameters and there's quite a few more hyperparameters compared to LightGCN\n",
    "- we want to find out why this is happening and whether we can bring these to LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056b1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SimpleX\"\n",
    "dataset = 'ml-100k'\n",
    "config_file_list = ['test0.yaml']\n",
    "config_dict = {\n",
    "    \"show_progress\": False,\n",
    "    \"log_wandb\":True,\n",
    "    \"eval_step\": 10,\n",
    "    \"epochs\": 50, \n",
    "    \"eval_args\": {\"split\": {\"RS\": [6,2,2]}},\n",
    "    \"valid_metric\":\"NDCG@20\",\n",
    "    \"metrics\":[\"Recall\",\"NDCG\"],\n",
    "    \"topk\":[10,20],\n",
    "    \n",
    "    \"embedding_size\":32,\n",
    "    \"margin\":0.8,\n",
    "    \"negative_weight\":100,\n",
    "    \"gamma\":0.6,\n",
    "    \"reg_weight\":0.001,\n",
    "    \"aggregator\":\"mean\",\n",
    "    \"history_len\":10,\n",
    "    \"neg_sampling\":{\"uniform\":100}\n",
    "}\n",
    "saved = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d927df95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\fyp0\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "03 Sep 11:52    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = C:\\Users\\tanch\\anaconda3\\envs\\fyp0\\Lib\\site-packages\\recbole\\config\\../dataset_example/ml-100k\n",
      "checkpoint_dir = saved/\n",
      "show_progress = False\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = True\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = {'uniform': 100}\n",
      "eval_step = 10\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [6, 2, 2]}, 'order': 'RO', 'group_by': 'user', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'NDCG']\n",
      "topk = [10, 20]\n",
      "valid_metric = NDCG@20\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = None\n",
      "item_inter_num_interval = None\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "worker = 0\n",
      "shuffle = True\n",
      "embedding_size = 32\n",
      "train_neg_sample_args = {'strategy': 'by', 'by': 100, 'distribution': 'uniform', 'dynamic': 'none'}\n",
      "margin = 0.8\n",
      "negative_weight = 100\n",
      "gamma = 0.6\n",
      "reg_weight = 0.001\n",
      "aggregator = mean\n",
      "history_len = 10\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "03 Sep 11:52    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "03 Sep 11:52    INFO  [Training]: train_batch_size = [2048] negative sampling: [{'uniform': 100}]\n",
      "03 Sep 11:52    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [6, 2, 2]}, 'order': 'RO', 'group_by': 'user', 'mode': 'full'}]\n",
      "03 Sep 11:52    WARNING  Max value of user's history interaction records has reached 26.322043969102793% of the total.\n",
      "03 Sep 11:52    INFO  SimpleX(\n",
      "  (user_emb): Embedding(944, 32)\n",
      "  (item_emb): Embedding(1683, 32, padding_idx=0)\n",
      "  (UI_map): Linear(in_features=32, out_features=32, bias=False)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (reg_loss): EmbLoss()\n",
      ")\n",
      "Trainable parameters: 85088\n",
      "03 Sep 11:52    ERROR  Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: chingfhen. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code\\wandb\\run-20220903_115252-2bvr8bqk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/recbole/runs/2bvr8bqk\" target=\"_blank\">valiant-microwave-8</a></strong> to <a href=\"https://wandb.ai/chingfhen/recbole\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03 Sep 11:53    INFO  epoch 0 training [time: 20.47s, train loss: 1242.0710]\n",
      "03 Sep 11:53    INFO  epoch 1 training [time: 17.26s, train loss: 821.8578]\n",
      "03 Sep 11:53    INFO  epoch 2 training [time: 17.08s, train loss: 800.3585]\n",
      "03 Sep 11:54    INFO  epoch 3 training [time: 17.74s, train loss: 785.2280]\n",
      "03 Sep 11:54    INFO  epoch 4 training [time: 17.30s, train loss: 775.0277]\n",
      "03 Sep 11:54    INFO  epoch 5 training [time: 17.19s, train loss: 769.0105]\n",
      "03 Sep 11:55    INFO  epoch 6 training [time: 17.80s, train loss: 763.7639]\n",
      "03 Sep 11:55    INFO  epoch 7 training [time: 18.25s, train loss: 758.6409]\n",
      "03 Sep 11:55    INFO  epoch 8 training [time: 17.26s, train loss: 756.0954]\n",
      "03 Sep 11:55    INFO  epoch 9 training [time: 18.01s, train loss: 752.6732]\n",
      "03 Sep 11:55    INFO  epoch 9 evaluating [time: 0.63s, valid_score: 0.230200]\n",
      "03 Sep 11:55    INFO  valid result: \n",
      "recall@10 : 0.1391    recall@20 : 0.2242    ndcg@10 : 0.2106    ndcg@20 : 0.2302\n",
      "03 Sep 11:56    INFO  epoch 10 training [time: 18.20s, train loss: 750.4606]\n",
      "03 Sep 11:56    INFO  epoch 11 training [time: 17.69s, train loss: 747.8259]\n",
      "03 Sep 11:56    INFO  epoch 12 training [time: 19.53s, train loss: 745.9820]\n",
      "03 Sep 11:57    INFO  epoch 13 training [time: 18.90s, train loss: 743.7820]\n",
      "03 Sep 11:57    INFO  epoch 14 training [time: 21.96s, train loss: 741.1730]\n",
      "03 Sep 11:57    INFO  epoch 15 training [time: 19.96s, train loss: 739.5648]\n",
      "03 Sep 11:58    INFO  epoch 16 training [time: 19.74s, train loss: 736.5943]\n",
      "03 Sep 11:58    INFO  epoch 17 training [time: 18.01s, train loss: 734.3831]\n",
      "03 Sep 11:58    INFO  epoch 18 training [time: 18.31s, train loss: 731.5662]\n",
      "03 Sep 11:59    INFO  epoch 19 training [time: 17.46s, train loss: 729.7531]\n",
      "03 Sep 11:59    INFO  epoch 19 evaluating [time: 0.63s, valid_score: 0.218900]\n",
      "03 Sep 11:59    INFO  valid result: \n",
      "recall@10 : 0.1324    recall@20 : 0.2224    ndcg@10 : 0.1945    ndcg@20 : 0.2189\n",
      "03 Sep 11:59    INFO  epoch 20 training [time: 20.00s, train loss: 726.7052]\n",
      "03 Sep 11:59    INFO  epoch 21 training [time: 19.86s, train loss: 723.8594]\n",
      "03 Sep 12:00    INFO  epoch 22 training [time: 19.23s, train loss: 721.9599]\n",
      "03 Sep 12:00    INFO  epoch 23 training [time: 19.25s, train loss: 720.2791]\n",
      "03 Sep 12:00    INFO  epoch 24 training [time: 18.06s, train loss: 718.6738]\n",
      "03 Sep 12:01    INFO  epoch 25 training [time: 17.59s, train loss: 717.5170]\n",
      "03 Sep 12:01    INFO  epoch 26 training [time: 17.52s, train loss: 715.5678]\n",
      "03 Sep 12:01    INFO  epoch 27 training [time: 17.69s, train loss: 715.0958]\n",
      "03 Sep 12:01    INFO  epoch 28 training [time: 17.52s, train loss: 713.7485]\n",
      "03 Sep 12:02    INFO  epoch 29 training [time: 17.31s, train loss: 713.0373]\n",
      "03 Sep 12:02    INFO  epoch 29 evaluating [time: 0.65s, valid_score: 0.227200]\n",
      "03 Sep 12:02    INFO  valid result: \n",
      "recall@10 : 0.1364    recall@20 : 0.2192    ndcg@10 : 0.2115    ndcg@20 : 0.2272\n",
      "03 Sep 12:02    INFO  epoch 30 training [time: 17.56s, train loss: 712.5129]\n",
      "03 Sep 12:02    INFO  epoch 31 training [time: 17.26s, train loss: 711.3620]\n",
      "03 Sep 12:03    INFO  epoch 32 training [time: 18.76s, train loss: 711.4491]\n",
      "03 Sep 12:03    INFO  epoch 33 training [time: 20.67s, train loss: 710.3698]\n",
      "03 Sep 12:03    INFO  epoch 34 training [time: 18.79s, train loss: 709.8051]\n",
      "03 Sep 12:04    INFO  epoch 35 training [time: 18.41s, train loss: 709.4920]\n",
      "03 Sep 12:04    INFO  epoch 36 training [time: 18.38s, train loss: 709.2248]\n",
      "03 Sep 12:04    INFO  epoch 37 training [time: 18.35s, train loss: 708.9030]\n",
      "03 Sep 12:05    INFO  epoch 38 training [time: 19.99s, train loss: 708.1898]\n",
      "03 Sep 12:05    INFO  epoch 39 training [time: 19.11s, train loss: 708.2206]\n",
      "03 Sep 12:05    INFO  epoch 39 evaluating [time: 0.81s, valid_score: 0.210600]\n",
      "03 Sep 12:05    INFO  valid result: \n",
      "recall@10 : 0.1253    recall@20 : 0.2087    ndcg@10 : 0.1908    ndcg@20 : 0.2106\n",
      "03 Sep 12:05    INFO  epoch 40 training [time: 19.43s, train loss: 707.6268]\n",
      "03 Sep 12:05    INFO  epoch 41 training [time: 19.53s, train loss: 707.0819]\n",
      "03 Sep 12:06    INFO  epoch 42 training [time: 18.33s, train loss: 708.2169]\n",
      "03 Sep 12:06    INFO  epoch 43 training [time: 19.78s, train loss: 707.3012]\n",
      "03 Sep 12:06    INFO  epoch 44 training [time: 18.95s, train loss: 707.0902]\n",
      "03 Sep 12:07    INFO  epoch 45 training [time: 19.96s, train loss: 706.8180]\n",
      "03 Sep 12:07    INFO  epoch 46 training [time: 20.19s, train loss: 706.9409]\n",
      "03 Sep 12:07    INFO  epoch 47 training [time: 20.19s, train loss: 706.1645]\n",
      "03 Sep 12:08    INFO  epoch 48 training [time: 17.99s, train loss: 706.1662]\n",
      "03 Sep 12:08    INFO  epoch 49 training [time: 22.21s, train loss: 705.9427]\n",
      "03 Sep 12:08    INFO  epoch 49 evaluating [time: 0.79s, valid_score: 0.204000]\n",
      "03 Sep 12:08    INFO  valid result: \n",
      "recall@10 : 0.1197    recall@20 : 0.2028    ndcg@10 : 0.1838    ndcg@20 : 0.204\n",
      "03 Sep 12:08    INFO  best valid : OrderedDict([('recall@10', 0.1391), ('recall@20', 0.2242), ('ndcg@10', 0.2106), ('ndcg@20', 0.2302)])\n",
      "03 Sep 12:08    INFO  test result: OrderedDict([('recall@10', 0.1322), ('recall@20', 0.2234), ('ndcg@10', 0.219), ('ndcg@20', 0.2353)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_valid_score': 0.2302,\n",
       " 'valid_score_bigger': True,\n",
       " 'best_valid_result': OrderedDict([('recall@10', 0.1391),\n",
       "              ('recall@20', 0.2242),\n",
       "              ('ndcg@10', 0.2106),\n",
       "              ('ndcg@20', 0.2302)]),\n",
       " 'test_result': OrderedDict([('recall@10', 0.1322),\n",
       "              ('recall@20', 0.2234),\n",
       "              ('ndcg@10', 0.219),\n",
       "              ('ndcg@20', 0.2353)])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "recbole.quick_start\n",
    "########################\n",
    "\"\"\"\n",
    "import logging\n",
    "from logging import getLogger\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation, save_split_dataloaders, load_split_dataloaders\n",
    "from recbole.utils import init_logger, get_model, get_trainer, init_seed, set_color\n",
    "\n",
    "\n",
    "# def run_recbole(model=None, dataset=None, config_file_list=None, config_dict=None, saved=True):\n",
    "\n",
    "# configurations initialization\n",
    "config = Config(model=model, dataset=dataset, config_file_list=config_file_list, config_dict=config_dict)\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "logger.info(config)\n",
    "\n",
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# model loading and initialization\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "model = get_model(config['model'])(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(\n",
    "    train_data, valid_data, saved=saved, show_progress=config['show_progress']\n",
    ")\n",
    "\n",
    "# model evaluation\n",
    "test_result = trainer.evaluate(test_data, load_best_model=saved, show_progress=config['show_progress'])\n",
    "\n",
    "logger.info(set_color('best valid ', 'yellow') + f': {best_valid_result}')\n",
    "logger.info(set_color('test result', 'yellow') + f': {test_result}')\n",
    "\n",
    "{\n",
    "    'best_valid_score': best_valid_score,\n",
    "    'valid_score_bigger': config['valid_metric_bigger'],\n",
    "    'best_valid_result': best_valid_result,\n",
    "    'test_result': test_result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f37da69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 64, 0.7, 300, 0.6, 0.1, 'mean', 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neg_seq_len, model.embedding_size, model.margin, model.negative_weight, model.gamma, model.reg_weight, model.aggregator, model.history_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2631efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f554cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parse_args() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython parse.py --model simplex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: parse_args() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "parse_args(\"python parse.py --model simplex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361f0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse = argparse.ArgumentParser(description=\"Choose model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00653ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_action_groups',\n",
       " '_actions',\n",
       " '_add_action',\n",
       " '_add_container_actions',\n",
       " '_check_conflict',\n",
       " '_check_value',\n",
       " '_defaults',\n",
       " '_get_args',\n",
       " '_get_formatter',\n",
       " '_get_handler',\n",
       " '_get_kwargs',\n",
       " '_get_nargs_pattern',\n",
       " '_get_option_tuples',\n",
       " '_get_optional_actions',\n",
       " '_get_optional_kwargs',\n",
       " '_get_positional_actions',\n",
       " '_get_positional_kwargs',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_handle_conflict_error',\n",
       " '_handle_conflict_resolve',\n",
       " '_has_negative_number_optionals',\n",
       " '_match_argument',\n",
       " '_match_arguments_partial',\n",
       " '_mutually_exclusive_groups',\n",
       " '_negative_number_matcher',\n",
       " '_option_string_actions',\n",
       " '_optionals',\n",
       " '_parse_known_args',\n",
       " '_parse_optional',\n",
       " '_pop_action_class',\n",
       " '_positionals',\n",
       " '_print_message',\n",
       " '_read_args_from_files',\n",
       " '_registries',\n",
       " '_registry_get',\n",
       " '_remove_action',\n",
       " '_subparsers',\n",
       " 'add_argument',\n",
       " 'add_argument_group',\n",
       " 'add_help',\n",
       " 'add_mutually_exclusive_group',\n",
       " 'add_subparsers',\n",
       " 'allow_abbrev',\n",
       " 'argument_default',\n",
       " 'conflict_handler',\n",
       " 'convert_arg_line_to_args',\n",
       " 'description',\n",
       " 'epilog',\n",
       " 'error',\n",
       " 'exit',\n",
       " 'exit_on_error',\n",
       " 'format_help',\n",
       " 'format_usage',\n",
       " 'formatter_class',\n",
       " 'fromfile_prefix_chars',\n",
       " 'get_default',\n",
       " 'parse_args',\n",
       " 'parse_intermixed_args',\n",
       " 'parse_known_args',\n",
       " 'parse_known_intermixed_args',\n",
       " 'prefix_chars',\n",
       " 'print_help',\n",
       " 'print_usage',\n",
       " 'prog',\n",
       " 'register',\n",
       " 'set_defaults',\n",
       " 'usage']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(parse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
