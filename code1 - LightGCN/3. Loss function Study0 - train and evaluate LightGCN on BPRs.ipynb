{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b5d606",
   "metadata": {},
   "source": [
    "# ABOUT:\n",
    "- this notebook **trains LightGCN on three different BPR loss functions to explore if increasing negative item weights can improve GNN performance in CF task**\n",
    "- Experiment details:\n",
    "    - i devised two alternative BPR loss functions to the original BPR\n",
    "    - steps:\n",
    "        1. uniformly sample loss_neg_weight from the range (1, 2]\n",
    "        2. perform a train test split on a unique seed\n",
    "        3. train and evaluate LightGCN each of the three BPR functions\n",
    "        4. Repeat steps 1-3 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760031bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.datasets.amazon_reviews import download_and_extract\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.constants import SEED as DEFAULT_SEED\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.utils.timer import Timer\n",
    "\n",
    "import pandas as pd\n",
    "from numpy.random import uniform, seed, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a868e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 1024\n",
    "SEED = DEFAULT_SEED  \n",
    "COL_USER = \"userID\"\n",
    "COL_ITEM = \"itemID\"\n",
    "\n",
    "yaml_file = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\config\\lightgcn.yml\"\n",
    "# user_file = \"../../tests/resources/deeprec/lightgcn/user_embeddings.csv\"\n",
    "# item_file = \"../../tests/resources/deeprec/lightgcn/item_embeddings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6587d9ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cfc174",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\data\\ml-latest-small\\ml-latest-small\\ratings.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.columns = [\"userID\", \"itemID\", \"rating\", \"timestamp\"] # better to follow the default colnames in the package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ff64f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run Loss Function Study\n",
    "- results are saved to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a717d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "loss_types = [\"OriginalBPR\", \"AmpBPR1\", \"AmpBPR2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6d309a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\fyp1\\lib\\site-packages\\recommenders\\models\\deeprec\\DataModel\\ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchingfhen\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_113552-1hcf5ajh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1hcf5ajh\" target=\"_blank\">experiment_OriginalBPR_1.4170220047025741_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)6.0s: train loss = 0.36234 = (mf)0.36198 + (embed)0.00037\n",
      "Epoch 2 (train)5.3s: train loss = 0.20207 = (mf)0.20132 + (embed)0.00075\n",
      "Epoch 3 (train)5.0s: train loss = 0.17152 = (mf)0.17057 + (embed)0.00095\n",
      "Epoch 4 (train)5.1s: train loss = 0.15649 = (mf)0.15534 + (embed)0.00115\n",
      "Epoch 5 (train)5.0s + (eval)0.4s: train loss = 0.14465 = (mf)0.14330 + (embed)0.00135, recall = 0.10222, ndcg = 0.21258, precision = 0.18049, map = 0.05642\n",
      "Epoch 6 (train)4.9s: train loss = 0.13715 = (mf)0.13561 + (embed)0.00154\n",
      "Epoch 7 (train)4.9s: train loss = 0.12988 = (mf)0.12816 + (embed)0.00172\n",
      "Epoch 8 (train)4.9s: train loss = 0.12030 = (mf)0.11838 + (embed)0.00192\n",
      "Epoch 9 (train)4.9s: train loss = 0.11208 = (mf)0.10994 + (embed)0.00214\n",
      "Epoch 10 (train)5.0s + (eval)0.3s: train loss = 0.10695 = (mf)0.10461 + (embed)0.00234, recall = 0.11840, ndcg = 0.23426, precision = 0.20115, map = 0.06733\n",
      "Epoch 11 (train)5.0s: train loss = 0.09953 = (mf)0.09696 + (embed)0.00257\n",
      "Epoch 12 (train)5.4s: train loss = 0.09490 = (mf)0.09210 + (embed)0.00280\n",
      "Epoch 13 (train)5.2s: train loss = 0.08760 = (mf)0.08455 + (embed)0.00305\n",
      "Epoch 14 (train)5.0s: train loss = 0.08127 = (mf)0.07797 + (embed)0.00331\n",
      "Epoch 15 (train)5.0s + (eval)0.2s: train loss = 0.07831 = (mf)0.07477 + (embed)0.00354, recall = 0.13155, ndcg = 0.26505, precision = 0.22525, map = 0.07494\n",
      "Epoch 16 (train)5.1s: train loss = 0.07386 = (mf)0.07009 + (embed)0.00377\n",
      "Epoch 17 (train)5.6s: train loss = 0.07150 = (mf)0.06752 + (embed)0.00398\n",
      "Epoch 18 (train)5.2s: train loss = 0.06888 = (mf)0.06470 + (embed)0.00418\n",
      "Epoch 19 (train)5.6s: train loss = 0.06535 = (mf)0.06096 + (embed)0.00439\n",
      "Epoch 20 (train)5.1s + (eval)0.2s: train loss = 0.06301 = (mf)0.05843 + (embed)0.00458, recall = 0.13663, ndcg = 0.27174, precision = 0.23295, map = 0.07568\n",
      "Epoch 21 (train)5.2s: train loss = 0.05953 = (mf)0.05477 + (embed)0.00476\n",
      "Epoch 22 (train)5.2s: train loss = 0.05665 = (mf)0.05169 + (embed)0.00495\n",
      "Epoch 23 (train)5.4s: train loss = 0.05699 = (mf)0.05187 + (embed)0.00512\n",
      "Epoch 24 (train)5.2s: train loss = 0.05537 = (mf)0.05008 + (embed)0.00529\n",
      "Epoch 25 (train)5.4s + (eval)0.3s: train loss = 0.05297 = (mf)0.04751 + (embed)0.00546, recall = 0.14409, ndcg = 0.28725, precision = 0.24721, map = 0.08303\n",
      "Epoch 26 (train)5.2s: train loss = 0.05216 = (mf)0.04658 + (embed)0.00558\n",
      "Epoch 27 (train)4.9s: train loss = 0.05167 = (mf)0.04595 + (embed)0.00572\n",
      "Epoch 28 (train)5.0s: train loss = 0.04855 = (mf)0.04268 + (embed)0.00587\n",
      "Epoch 29 (train)5.1s: train loss = 0.04878 = (mf)0.04276 + (embed)0.00602\n",
      "Epoch 30 (train)5.1s + (eval)0.2s: train loss = 0.04511 = (mf)0.03898 + (embed)0.00613, recall = 0.14484, ndcg = 0.29073, precision = 0.24967, map = 0.08439\n",
      "Epoch 31 (train)4.9s: train loss = 0.04656 = (mf)0.04030 + (embed)0.00625\n",
      "Epoch 32 (train)4.9s: train loss = 0.04373 = (mf)0.03736 + (embed)0.00637\n",
      "Epoch 33 (train)4.9s: train loss = 0.04440 = (mf)0.03791 + (embed)0.00649\n",
      "Epoch 34 (train)4.9s: train loss = 0.04310 = (mf)0.03651 + (embed)0.00659\n",
      "Epoch 35 (train)5.0s + (eval)0.2s: train loss = 0.04126 = (mf)0.03456 + (embed)0.00670, recall = 0.14450, ndcg = 0.28923, precision = 0.25279, map = 0.08231\n",
      "Epoch 36 (train)4.9s: train loss = 0.04238 = (mf)0.03560 + (embed)0.00678\n",
      "Epoch 37 (train)4.9s: train loss = 0.04050 = (mf)0.03364 + (embed)0.00687\n",
      "Epoch 38 (train)4.9s: train loss = 0.03991 = (mf)0.03293 + (embed)0.00697\n",
      "Epoch 39 (train)4.9s: train loss = 0.04027 = (mf)0.03320 + (embed)0.00707\n",
      "Epoch 40 (train)4.9s + (eval)0.2s: train loss = 0.03818 = (mf)0.03101 + (embed)0.00717, recall = 0.14791, ndcg = 0.29139, precision = 0.25262, map = 0.08487\n",
      "Epoch 41 (train)4.9s: train loss = 0.03714 = (mf)0.02989 + (embed)0.00725\n",
      "Epoch 42 (train)4.9s: train loss = 0.03846 = (mf)0.03113 + (embed)0.00733\n",
      "Epoch 43 (train)4.9s: train loss = 0.03764 = (mf)0.03025 + (embed)0.00739\n",
      "Epoch 44 (train)4.9s: train loss = 0.03641 = (mf)0.02893 + (embed)0.00747\n",
      "Epoch 45 (train)4.9s + (eval)0.3s: train loss = 0.03622 = (mf)0.02867 + (embed)0.00754, recall = 0.15037, ndcg = 0.29635, precision = 0.25262, map = 0.08838\n",
      "Epoch 46 (train)4.9s: train loss = 0.03548 = (mf)0.02788 + (embed)0.00760\n",
      "Epoch 47 (train)5.0s: train loss = 0.03624 = (mf)0.02860 + (embed)0.00764\n",
      "Epoch 48 (train)4.9s: train loss = 0.03512 = (mf)0.02742 + (embed)0.00771\n",
      "Epoch 49 (train)4.9s: train loss = 0.03428 = (mf)0.02652 + (embed)0.00776\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.03448 = (mf)0.02666 + (embed)0.00782, recall = 0.14836, ndcg = 0.29205, precision = 0.25115, map = 0.08583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9134a918c1044ed28edd97a69fbd685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▁▁▃▁▁▁▂▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▃▅▅▇▇▇▇█▇</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▃▅▆▇█▇███</td></tr><tr><td>precision</td><td>▁▃▅▆▇█████</td></tr><tr><td>recall</td><td>▁▃▅▆▇▇▇███</td></tr><tr><td>train_time</td><td>█▃▁▂▁▁▁▁▂▄▃▁▂▆▃▅▃▃▄▃▃▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00782</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.24356</td></tr><tr><td>loss</td><td>0.03448</td></tr><tr><td>map</td><td>0.08583</td></tr><tr><td>mf_loss</td><td>0.02666</td></tr><tr><td>ndcg</td><td>0.29205</td></tr><tr><td>precision</td><td>0.25115</td></tr><tr><td>recall</td><td>0.14836</td></tr><tr><td>train_time</td><td>4.91484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_OriginalBPR_1.4170220047025741_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1hcf5ajh\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1hcf5ajh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_113552-1hcf5ajh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb39398a2dd45b7999724fdb9401fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_114025-9cfioudy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/9cfioudy\" target=\"_blank\">experiment_AmpBPR1_1.4170220047025741_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.4s: train loss = 0.34464 = (mf)0.34433 + (embed)0.00030\n",
      "Epoch 2 (train)5.0s: train loss = 0.20263 = (mf)0.20207 + (embed)0.00057\n",
      "Epoch 3 (train)4.9s: train loss = 0.17270 = (mf)0.17195 + (embed)0.00075\n",
      "Epoch 4 (train)4.9s: train loss = 0.14571 = (mf)0.14472 + (embed)0.00098\n",
      "Epoch 5 (train)4.9s + (eval)0.3s: train loss = 0.12869 = (mf)0.12748 + (embed)0.00121, recall = 0.10719, ndcg = 0.22452, precision = 0.19262, map = 0.06171\n",
      "Epoch 6 (train)5.0s: train loss = 0.11747 = (mf)0.11606 + (embed)0.00141\n",
      "Epoch 7 (train)5.0s: train loss = 0.10976 = (mf)0.10818 + (embed)0.00158\n",
      "Epoch 8 (train)4.9s: train loss = 0.10711 = (mf)0.10539 + (embed)0.00173\n",
      "Epoch 9 (train)4.9s: train loss = 0.09938 = (mf)0.09749 + (embed)0.00189\n",
      "Epoch 10 (train)4.9s + (eval)0.2s: train loss = 0.09273 = (mf)0.09069 + (embed)0.00205, recall = 0.11188, ndcg = 0.22899, precision = 0.20098, map = 0.06019\n",
      "Epoch 11 (train)4.9s: train loss = 0.08586 = (mf)0.08363 + (embed)0.00224\n",
      "Epoch 12 (train)4.9s: train loss = 0.08038 = (mf)0.07796 + (embed)0.00242\n",
      "Epoch 13 (train)4.9s: train loss = 0.07591 = (mf)0.07331 + (embed)0.00260\n",
      "Epoch 14 (train)4.9s: train loss = 0.07258 = (mf)0.06979 + (embed)0.00278\n",
      "Epoch 15 (train)4.9s + (eval)0.2s: train loss = 0.06958 = (mf)0.06662 + (embed)0.00296, recall = 0.12717, ndcg = 0.25268, precision = 0.21934, map = 0.06971\n",
      "Epoch 16 (train)4.9s: train loss = 0.06305 = (mf)0.05990 + (embed)0.00315\n",
      "Epoch 17 (train)4.9s: train loss = 0.06107 = (mf)0.05774 + (embed)0.00333\n",
      "Epoch 18 (train)4.9s: train loss = 0.05822 = (mf)0.05472 + (embed)0.00350\n",
      "Epoch 19 (train)4.9s: train loss = 0.05703 = (mf)0.05337 + (embed)0.00367\n",
      "Epoch 20 (train)4.9s + (eval)0.2s: train loss = 0.05374 = (mf)0.04992 + (embed)0.00382, recall = 0.14382, ndcg = 0.28006, precision = 0.24230, map = 0.08134\n",
      "Epoch 21 (train)4.9s: train loss = 0.05084 = (mf)0.04687 + (embed)0.00397\n",
      "Epoch 22 (train)4.9s: train loss = 0.04911 = (mf)0.04499 + (embed)0.00412\n",
      "Epoch 23 (train)4.9s: train loss = 0.04783 = (mf)0.04358 + (embed)0.00426\n",
      "Epoch 24 (train)4.9s: train loss = 0.04640 = (mf)0.04199 + (embed)0.00440\n",
      "Epoch 25 (train)4.9s + (eval)0.2s: train loss = 0.04635 = (mf)0.04182 + (embed)0.00453, recall = 0.14284, ndcg = 0.28106, precision = 0.24066, map = 0.08284\n",
      "Epoch 26 (train)4.9s: train loss = 0.04299 = (mf)0.03834 + (embed)0.00465\n",
      "Epoch 27 (train)4.9s: train loss = 0.04346 = (mf)0.03868 + (embed)0.00477\n",
      "Epoch 28 (train)4.9s: train loss = 0.04083 = (mf)0.03593 + (embed)0.00490\n",
      "Epoch 29 (train)4.9s: train loss = 0.04259 = (mf)0.03758 + (embed)0.00501\n",
      "Epoch 30 (train)4.9s + (eval)0.2s: train loss = 0.04124 = (mf)0.03613 + (embed)0.00511, recall = 0.14538, ndcg = 0.28304, precision = 0.24443, map = 0.08419\n",
      "Epoch 31 (train)4.9s: train loss = 0.03861 = (mf)0.03342 + (embed)0.00519\n",
      "Epoch 32 (train)4.9s: train loss = 0.03852 = (mf)0.03322 + (embed)0.00530\n",
      "Epoch 33 (train)4.9s: train loss = 0.03775 = (mf)0.03238 + (embed)0.00537\n",
      "Epoch 34 (train)4.9s: train loss = 0.03819 = (mf)0.03274 + (embed)0.00545\n",
      "Epoch 35 (train)5.1s + (eval)0.2s: train loss = 0.03622 = (mf)0.03068 + (embed)0.00554, recall = 0.14759, ndcg = 0.28372, precision = 0.24508, map = 0.08481\n",
      "Epoch 36 (train)5.3s: train loss = 0.03576 = (mf)0.03013 + (embed)0.00563\n",
      "Epoch 37 (train)5.2s: train loss = 0.03599 = (mf)0.03027 + (embed)0.00572\n",
      "Epoch 38 (train)4.9s: train loss = 0.03355 = (mf)0.02777 + (embed)0.00578\n",
      "Epoch 39 (train)5.0s: train loss = 0.03394 = (mf)0.02808 + (embed)0.00586\n",
      "Epoch 40 (train)4.9s + (eval)0.2s: train loss = 0.03265 = (mf)0.02673 + (embed)0.00592, recall = 0.14509, ndcg = 0.29167, precision = 0.24787, map = 0.08642\n",
      "Epoch 41 (train)4.9s: train loss = 0.03260 = (mf)0.02660 + (embed)0.00600\n",
      "Epoch 42 (train)5.2s: train loss = 0.03263 = (mf)0.02656 + (embed)0.00607\n",
      "Epoch 43 (train)5.0s: train loss = 0.03248 = (mf)0.02636 + (embed)0.00612\n",
      "Epoch 44 (train)5.2s: train loss = 0.03121 = (mf)0.02504 + (embed)0.00617\n",
      "Epoch 45 (train)5.4s + (eval)0.3s: train loss = 0.03119 = (mf)0.02496 + (embed)0.00623, recall = 0.14773, ndcg = 0.29214, precision = 0.25197, map = 0.08625\n",
      "Epoch 46 (train)5.0s: train loss = 0.03160 = (mf)0.02534 + (embed)0.00626\n",
      "Epoch 47 (train)5.0s: train loss = 0.03102 = (mf)0.02473 + (embed)0.00628\n",
      "Epoch 48 (train)5.1s: train loss = 0.03009 = (mf)0.02375 + (embed)0.00634\n",
      "Epoch 49 (train)5.0s: train loss = 0.02957 = (mf)0.02318 + (embed)0.00639\n",
      "Epoch 50 (train)5.2s + (eval)0.3s: train loss = 0.03043 = (mf)0.02399 + (embed)0.00644, recall = 0.14494, ndcg = 0.28673, precision = 0.24639, map = 0.08488\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c163808dac475c82770fe9215b8216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▁▁▂▁▂▂▅▇</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▁▄▇▇▇████</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▁▄▇▇▇▇██▇</td></tr><tr><td>precision</td><td>▁▂▄▇▇▇▇██▇</td></tr><tr><td>recall</td><td>▁▂▄▇▇█████</td></tr><tr><td>train_time</td><td>█▃▂▂▃▂▂▁▁▁▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▇▆▂▂▁▆▃▆▃▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00644</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.32633</td></tr><tr><td>loss</td><td>0.03043</td></tr><tr><td>map</td><td>0.08488</td></tr><tr><td>mf_loss</td><td>0.02399</td></tr><tr><td>ndcg</td><td>0.28673</td></tr><tr><td>precision</td><td>0.24639</td></tr><tr><td>recall</td><td>0.14494</td></tr><tr><td>train_time</td><td>5.1741</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR1_1.4170220047025741_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/9cfioudy\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/9cfioudy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_114025-9cfioudy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46476b17ab5140ebb02ffe9d3822ccc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_114451-1tk1uzgl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1tk1uzgl\" target=\"_blank\">experiment_AmpBPR2_1.4170220047025741_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.43732 = (mf)0.43700 + (embed)0.00031\n",
      "Epoch 2 (train)4.9s: train loss = 0.26390 = (mf)0.26319 + (embed)0.00071\n",
      "Epoch 3 (train)4.9s: train loss = 0.23004 = (mf)0.22909 + (embed)0.00095\n",
      "Epoch 4 (train)4.9s: train loss = 0.21083 = (mf)0.20969 + (embed)0.00114\n",
      "Epoch 5 (train)5.0s + (eval)0.4s: train loss = 0.19622 = (mf)0.19490 + (embed)0.00132, recall = 0.10162, ndcg = 0.21889, precision = 0.18295, map = 0.05752\n",
      "Epoch 6 (train)5.0s: train loss = 0.18728 = (mf)0.18581 + (embed)0.00147\n",
      "Epoch 7 (train)5.1s: train loss = 0.17776 = (mf)0.17613 + (embed)0.00163\n",
      "Epoch 8 (train)4.9s: train loss = 0.17213 = (mf)0.17033 + (embed)0.00180\n",
      "Epoch 9 (train)5.1s: train loss = 0.15870 = (mf)0.15670 + (embed)0.00199\n",
      "Epoch 10 (train)4.9s + (eval)0.3s: train loss = 0.14624 = (mf)0.14404 + (embed)0.00220, recall = 0.11590, ndcg = 0.23973, precision = 0.20557, map = 0.06347\n",
      "Epoch 11 (train)5.0s: train loss = 0.14262 = (mf)0.14023 + (embed)0.00239\n",
      "Epoch 12 (train)5.0s: train loss = 0.13070 = (mf)0.12809 + (embed)0.00261\n",
      "Epoch 13 (train)5.2s: train loss = 0.12938 = (mf)0.12656 + (embed)0.00281\n",
      "Epoch 14 (train)4.9s: train loss = 0.12185 = (mf)0.11883 + (embed)0.00302\n",
      "Epoch 15 (train)4.9s + (eval)0.3s: train loss = 0.11605 = (mf)0.11283 + (embed)0.00322, recall = 0.13947, ndcg = 0.27513, precision = 0.24000, map = 0.07696\n",
      "Epoch 16 (train)4.9s: train loss = 0.11175 = (mf)0.10832 + (embed)0.00342\n",
      "Epoch 17 (train)4.9s: train loss = 0.10528 = (mf)0.10164 + (embed)0.00364\n",
      "Epoch 18 (train)4.9s: train loss = 0.10417 = (mf)0.10033 + (embed)0.00383\n",
      "Epoch 19 (train)4.9s: train loss = 0.10044 = (mf)0.09641 + (embed)0.00403\n",
      "Epoch 20 (train)4.9s + (eval)0.2s: train loss = 0.09565 = (mf)0.09143 + (embed)0.00422, recall = 0.14390, ndcg = 0.29030, precision = 0.25082, map = 0.08283\n",
      "Epoch 21 (train)4.9s: train loss = 0.09310 = (mf)0.08869 + (embed)0.00441\n",
      "Epoch 22 (train)4.9s: train loss = 0.09094 = (mf)0.08636 + (embed)0.00458\n",
      "Epoch 23 (train)4.9s: train loss = 0.08790 = (mf)0.08316 + (embed)0.00474\n",
      "Epoch 24 (train)5.0s: train loss = 0.08596 = (mf)0.08104 + (embed)0.00491\n",
      "Epoch 25 (train)4.9s + (eval)0.2s: train loss = 0.08424 = (mf)0.07916 + (embed)0.00508, recall = 0.14891, ndcg = 0.29358, precision = 0.25557, map = 0.08432\n",
      "Epoch 26 (train)4.9s: train loss = 0.08207 = (mf)0.07683 + (embed)0.00524\n",
      "Epoch 27 (train)4.9s: train loss = 0.07966 = (mf)0.07426 + (embed)0.00540\n",
      "Epoch 28 (train)4.9s: train loss = 0.07662 = (mf)0.07107 + (embed)0.00555\n",
      "Epoch 29 (train)4.9s: train loss = 0.07876 = (mf)0.07306 + (embed)0.00570\n",
      "Epoch 30 (train)5.0s + (eval)0.2s: train loss = 0.07493 = (mf)0.06909 + (embed)0.00583, recall = 0.14945, ndcg = 0.29823, precision = 0.25623, map = 0.08811\n",
      "Epoch 31 (train)5.1s: train loss = 0.07509 = (mf)0.06913 + (embed)0.00596\n",
      "Epoch 32 (train)4.9s: train loss = 0.07466 = (mf)0.06857 + (embed)0.00608\n",
      "Epoch 33 (train)4.9s: train loss = 0.07298 = (mf)0.06676 + (embed)0.00622\n",
      "Epoch 34 (train)4.9s: train loss = 0.07092 = (mf)0.06458 + (embed)0.00634\n",
      "Epoch 35 (train)4.9s + (eval)0.2s: train loss = 0.07197 = (mf)0.06554 + (embed)0.00644, recall = 0.14682, ndcg = 0.29921, precision = 0.25574, map = 0.08706\n",
      "Epoch 36 (train)5.0s: train loss = 0.06739 = (mf)0.06083 + (embed)0.00656\n",
      "Epoch 37 (train)5.1s: train loss = 0.06781 = (mf)0.06113 + (embed)0.00667\n",
      "Epoch 38 (train)4.9s: train loss = 0.06684 = (mf)0.06006 + (embed)0.00678\n",
      "Epoch 39 (train)5.0s: train loss = 0.06716 = (mf)0.06027 + (embed)0.00689\n",
      "Epoch 40 (train)4.9s + (eval)0.3s: train loss = 0.06550 = (mf)0.05850 + (embed)0.00700, recall = 0.14650, ndcg = 0.29830, precision = 0.25459, map = 0.08760\n",
      "Epoch 41 (train)4.9s: train loss = 0.06539 = (mf)0.05829 + (embed)0.00711\n",
      "Epoch 42 (train)4.9s: train loss = 0.06637 = (mf)0.05917 + (embed)0.00720\n",
      "Epoch 43 (train)4.9s: train loss = 0.06350 = (mf)0.05620 + (embed)0.00730\n",
      "Epoch 44 (train)4.9s: train loss = 0.06405 = (mf)0.05668 + (embed)0.00738\n",
      "Epoch 45 (train)4.9s + (eval)0.3s: train loss = 0.06342 = (mf)0.05596 + (embed)0.00746, recall = 0.15072, ndcg = 0.30136, precision = 0.25803, map = 0.08945\n",
      "Epoch 46 (train)4.9s: train loss = 0.06306 = (mf)0.05550 + (embed)0.00756\n",
      "Epoch 47 (train)4.9s: train loss = 0.06167 = (mf)0.05404 + (embed)0.00763\n",
      "Epoch 48 (train)4.9s: train loss = 0.06214 = (mf)0.05445 + (embed)0.00769\n",
      "Epoch 49 (train)5.0s: train loss = 0.05984 = (mf)0.05206 + (embed)0.00778\n",
      "Epoch 50 (train)5.0s + (eval)0.3s: train loss = 0.06112 = (mf)0.05326 + (embed)0.00786, recall = 0.15104, ndcg = 0.29949, precision = 0.25787, map = 0.08875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▃▁▁▁▁▁▁▄</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▂▅▇▇█▇███</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▃▆▇▇█████</td></tr><tr><td>precision</td><td>▁▃▆▇██████</td></tr><tr><td>recall</td><td>▁▃▆▇██▇▇██</td></tr><tr><td>train_time</td><td>█▁▁▁▃▅▂▅▃▄█▂▂▂▂▁▂▂▁▃▁▁▂▂▅▁▂▂▃▅▁▃▁▂▂▂▂▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00786</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.29374</td></tr><tr><td>loss</td><td>0.06112</td></tr><tr><td>map</td><td>0.08875</td></tr><tr><td>mf_loss</td><td>0.05326</td></tr><tr><td>ndcg</td><td>0.29949</td></tr><tr><td>precision</td><td>0.25787</td></tr><tr><td>recall</td><td>0.15104</td></tr><tr><td>train_time</td><td>4.95292</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR2_1.4170220047025741_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1tk1uzgl\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1tk1uzgl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_114451-1tk1uzgl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\fyp1\\lib\\site-packages\\recommenders\\models\\deeprec\\DataModel\\ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_114919-2l0emt5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2l0emt5w\" target=\"_blank\">experiment_OriginalBPR_1.7912694364187152_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.3s: train loss = 0.36617 = (mf)0.36581 + (embed)0.00036\n",
      "Epoch 2 (train)5.0s: train loss = 0.20165 = (mf)0.20089 + (embed)0.00076\n",
      "Epoch 3 (train)5.2s: train loss = 0.17643 = (mf)0.17546 + (embed)0.00097\n",
      "Epoch 4 (train)5.1s: train loss = 0.15438 = (mf)0.15318 + (embed)0.00120\n",
      "Epoch 5 (train)5.0s + (eval)0.3s: train loss = 0.14072 = (mf)0.13930 + (embed)0.00143, recall = 0.10806, ndcg = 0.23894, precision = 0.20656, map = 0.06005\n",
      "Epoch 6 (train)5.0s: train loss = 0.13243 = (mf)0.13081 + (embed)0.00161\n",
      "Epoch 7 (train)5.0s: train loss = 0.12669 = (mf)0.12489 + (embed)0.00180\n",
      "Epoch 8 (train)5.0s: train loss = 0.11795 = (mf)0.11597 + (embed)0.00198\n",
      "Epoch 9 (train)5.0s: train loss = 0.11200 = (mf)0.10982 + (embed)0.00217\n",
      "Epoch 10 (train)5.2s + (eval)0.2s: train loss = 0.10605 = (mf)0.10367 + (embed)0.00238, recall = 0.11467, ndcg = 0.25041, precision = 0.21492, map = 0.06692\n",
      "Epoch 11 (train)5.0s: train loss = 0.09769 = (mf)0.09510 + (embed)0.00259\n",
      "Epoch 12 (train)4.9s: train loss = 0.09366 = (mf)0.09084 + (embed)0.00282\n",
      "Epoch 13 (train)4.9s: train loss = 0.08611 = (mf)0.08307 + (embed)0.00304\n",
      "Epoch 14 (train)5.1s: train loss = 0.08157 = (mf)0.07829 + (embed)0.00329\n",
      "Epoch 15 (train)5.1s + (eval)0.2s: train loss = 0.07711 = (mf)0.07358 + (embed)0.00353, recall = 0.12928, ndcg = 0.27520, precision = 0.23836, map = 0.07456\n",
      "Epoch 16 (train)4.9s: train loss = 0.07391 = (mf)0.07015 + (embed)0.00375\n",
      "Epoch 17 (train)4.9s: train loss = 0.07139 = (mf)0.06743 + (embed)0.00396\n",
      "Epoch 18 (train)5.0s: train loss = 0.06772 = (mf)0.06354 + (embed)0.00417\n",
      "Epoch 19 (train)4.9s: train loss = 0.06617 = (mf)0.06180 + (embed)0.00437\n",
      "Epoch 20 (train)4.9s + (eval)0.2s: train loss = 0.06206 = (mf)0.05751 + (embed)0.00455, recall = 0.13730, ndcg = 0.29065, precision = 0.25328, map = 0.07901\n",
      "Epoch 21 (train)4.9s: train loss = 0.05999 = (mf)0.05524 + (embed)0.00475\n",
      "Epoch 22 (train)4.9s: train loss = 0.05543 = (mf)0.05050 + (embed)0.00493\n",
      "Epoch 23 (train)4.9s: train loss = 0.05588 = (mf)0.05077 + (embed)0.00510\n",
      "Epoch 24 (train)4.9s: train loss = 0.05515 = (mf)0.04990 + (embed)0.00525\n",
      "Epoch 25 (train)4.9s + (eval)0.2s: train loss = 0.05221 = (mf)0.04680 + (embed)0.00540, recall = 0.14336, ndcg = 0.29829, precision = 0.25541, map = 0.08327\n",
      "Epoch 26 (train)4.9s: train loss = 0.05106 = (mf)0.04549 + (embed)0.00557\n",
      "Epoch 27 (train)4.9s: train loss = 0.05149 = (mf)0.04578 + (embed)0.00571\n",
      "Epoch 28 (train)4.9s: train loss = 0.04658 = (mf)0.04071 + (embed)0.00587\n",
      "Epoch 29 (train)5.2s: train loss = 0.04820 = (mf)0.04220 + (embed)0.00600\n",
      "Epoch 30 (train)5.0s + (eval)0.2s: train loss = 0.04468 = (mf)0.03854 + (embed)0.00614, recall = 0.14543, ndcg = 0.30302, precision = 0.25918, map = 0.08521\n",
      "Epoch 31 (train)5.0s: train loss = 0.04541 = (mf)0.03916 + (embed)0.00625\n",
      "Epoch 32 (train)5.2s: train loss = 0.04536 = (mf)0.03900 + (embed)0.00636\n",
      "Epoch 33 (train)5.0s: train loss = 0.04497 = (mf)0.03851 + (embed)0.00646\n",
      "Epoch 34 (train)5.0s: train loss = 0.04151 = (mf)0.03493 + (embed)0.00658\n",
      "Epoch 35 (train)5.0s + (eval)0.2s: train loss = 0.04159 = (mf)0.03490 + (embed)0.00668, recall = 0.14584, ndcg = 0.30082, precision = 0.25803, map = 0.08552\n",
      "Epoch 36 (train)5.0s: train loss = 0.04125 = (mf)0.03445 + (embed)0.00680\n",
      "Epoch 37 (train)5.0s: train loss = 0.04054 = (mf)0.03364 + (embed)0.00690\n",
      "Epoch 38 (train)5.0s: train loss = 0.03932 = (mf)0.03234 + (embed)0.00699\n",
      "Epoch 39 (train)5.2s: train loss = 0.03937 = (mf)0.03230 + (embed)0.00707\n",
      "Epoch 40 (train)5.2s + (eval)0.3s: train loss = 0.03861 = (mf)0.03147 + (embed)0.00714, recall = 0.14712, ndcg = 0.30008, precision = 0.25607, map = 0.08520\n",
      "Epoch 41 (train)5.1s: train loss = 0.03812 = (mf)0.03090 + (embed)0.00721\n",
      "Epoch 42 (train)5.1s: train loss = 0.03744 = (mf)0.03015 + (embed)0.00729\n",
      "Epoch 43 (train)5.2s: train loss = 0.03743 = (mf)0.03006 + (embed)0.00737\n",
      "Epoch 44 (train)5.0s: train loss = 0.03691 = (mf)0.02946 + (embed)0.00745\n",
      "Epoch 45 (train)5.2s + (eval)0.3s: train loss = 0.03595 = (mf)0.02844 + (embed)0.00751, recall = 0.15245, ndcg = 0.30717, precision = 0.26344, map = 0.08925\n",
      "Epoch 46 (train)5.1s: train loss = 0.03574 = (mf)0.02816 + (embed)0.00758\n",
      "Epoch 47 (train)5.0s: train loss = 0.03608 = (mf)0.02846 + (embed)0.00762\n",
      "Epoch 48 (train)4.9s: train loss = 0.03563 = (mf)0.02794 + (embed)0.00769\n",
      "Epoch 49 (train)4.9s: train loss = 0.03386 = (mf)0.02612 + (embed)0.00774\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.03380 = (mf)0.02598 + (embed)0.00782, recall = 0.14698, ndcg = 0.29846, precision = 0.25557, map = 0.08543\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5723ad1f1514bedae76301164d0a79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▁▂▂▁▁▃▃▂</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▃▄▆▇▇▇▇█▇</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▂▅▆▇█▇▇█▇</td></tr><tr><td>precision</td><td>▁▂▅▇▇▇▇▇█▇</td></tr><tr><td>recall</td><td>▁▂▄▆▇▇▇▇█▇</td></tr><tr><td>train_time</td><td>█▄▇▅▄▃▄▄▂▂▂▄▁▂▂▂▂▁▁▁▁▂▂▆▃▆▃▄▃▃▃▇▄▅▆▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00782</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.2372</td></tr><tr><td>loss</td><td>0.0338</td></tr><tr><td>map</td><td>0.08543</td></tr><tr><td>mf_loss</td><td>0.02598</td></tr><tr><td>ndcg</td><td>0.29846</td></tr><tr><td>precision</td><td>0.25557</td></tr><tr><td>recall</td><td>0.14698</td></tr><tr><td>train_time</td><td>4.87695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_OriginalBPR_1.7912694364187152_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2l0emt5w\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2l0emt5w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_114919-2l0emt5w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09aceb07fe64ccc9ed0b3fa9993efdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333336530875, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_115345-2s8g9yp4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2s8g9yp4\" target=\"_blank\">experiment_AmpBPR1_1.7912694364187152_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.1s: train loss = 0.33489 = (mf)0.33462 + (embed)0.00027\n",
      "Epoch 2 (train)5.0s: train loss = 0.19637 = (mf)0.19590 + (embed)0.00047\n",
      "Epoch 3 (train)4.9s: train loss = 0.16017 = (mf)0.15953 + (embed)0.00065\n",
      "Epoch 4 (train)5.1s: train loss = 0.14485 = (mf)0.14403 + (embed)0.00082\n",
      "Epoch 5 (train)5.2s + (eval)0.4s: train loss = 0.13343 = (mf)0.13245 + (embed)0.00098, recall = 0.10749, ndcg = 0.23054, precision = 0.20197, map = 0.05766\n",
      "Epoch 6 (train)4.9s: train loss = 0.11494 = (mf)0.11379 + (embed)0.00115\n",
      "Epoch 7 (train)5.0s: train loss = 0.10900 = (mf)0.10769 + (embed)0.00132\n",
      "Epoch 8 (train)5.1s: train loss = 0.09785 = (mf)0.09637 + (embed)0.00148\n",
      "Epoch 9 (train)5.0s: train loss = 0.09159 = (mf)0.08993 + (embed)0.00166\n",
      "Epoch 10 (train)4.9s + (eval)0.2s: train loss = 0.08518 = (mf)0.08335 + (embed)0.00184, recall = 0.12404, ndcg = 0.25738, precision = 0.22492, map = 0.07079\n",
      "Epoch 11 (train)4.9s: train loss = 0.07754 = (mf)0.07553 + (embed)0.00201\n",
      "Epoch 12 (train)5.0s: train loss = 0.07310 = (mf)0.07092 + (embed)0.00218\n",
      "Epoch 13 (train)4.9s: train loss = 0.06559 = (mf)0.06325 + (embed)0.00235\n",
      "Epoch 14 (train)4.9s: train loss = 0.06500 = (mf)0.06249 + (embed)0.00251\n",
      "Epoch 15 (train)4.9s + (eval)0.3s: train loss = 0.05960 = (mf)0.05691 + (embed)0.00269, recall = 0.14290, ndcg = 0.29208, precision = 0.25262, map = 0.08336\n",
      "Epoch 16 (train)5.0s: train loss = 0.05590 = (mf)0.05306 + (embed)0.00285\n",
      "Epoch 17 (train)5.0s: train loss = 0.05410 = (mf)0.05110 + (embed)0.00300\n",
      "Epoch 18 (train)4.9s: train loss = 0.05144 = (mf)0.04830 + (embed)0.00314\n",
      "Epoch 19 (train)5.0s: train loss = 0.05006 = (mf)0.04679 + (embed)0.00327\n",
      "Epoch 20 (train)5.0s + (eval)0.2s: train loss = 0.04658 = (mf)0.04317 + (embed)0.00342, recall = 0.14408, ndcg = 0.29248, precision = 0.24902, map = 0.08514\n",
      "Epoch 21 (train)4.9s: train loss = 0.04623 = (mf)0.04269 + (embed)0.00354\n",
      "Epoch 22 (train)5.0s: train loss = 0.04366 = (mf)0.03999 + (embed)0.00367\n",
      "Epoch 23 (train)4.9s: train loss = 0.04233 = (mf)0.03855 + (embed)0.00379\n",
      "Epoch 24 (train)4.9s: train loss = 0.04076 = (mf)0.03685 + (embed)0.00390\n",
      "Epoch 25 (train)5.1s + (eval)0.3s: train loss = 0.04018 = (mf)0.03619 + (embed)0.00399, recall = 0.14729, ndcg = 0.30298, precision = 0.25967, map = 0.08607\n",
      "Epoch 26 (train)5.1s: train loss = 0.03752 = (mf)0.03342 + (embed)0.00410\n",
      "Epoch 27 (train)5.1s: train loss = 0.03781 = (mf)0.03361 + (embed)0.00419\n",
      "Epoch 28 (train)5.1s: train loss = 0.03646 = (mf)0.03216 + (embed)0.00430\n",
      "Epoch 29 (train)5.0s: train loss = 0.03552 = (mf)0.03114 + (embed)0.00438\n",
      "Epoch 30 (train)4.9s + (eval)0.2s: train loss = 0.03637 = (mf)0.03191 + (embed)0.00446, recall = 0.14577, ndcg = 0.29673, precision = 0.25639, map = 0.08408\n",
      "Epoch 31 (train)5.0s: train loss = 0.03591 = (mf)0.03136 + (embed)0.00455\n",
      "Epoch 32 (train)5.1s: train loss = 0.03447 = (mf)0.02984 + (embed)0.00463\n",
      "Epoch 33 (train)5.0s: train loss = 0.03504 = (mf)0.03035 + (embed)0.00469\n",
      "Epoch 34 (train)5.0s: train loss = 0.03330 = (mf)0.02855 + (embed)0.00475\n",
      "Epoch 35 (train)4.9s + (eval)0.2s: train loss = 0.03193 = (mf)0.02710 + (embed)0.00483, recall = 0.14387, ndcg = 0.29493, precision = 0.25098, map = 0.08370\n",
      "Epoch 36 (train)5.1s: train loss = 0.03331 = (mf)0.02841 + (embed)0.00490\n",
      "Epoch 37 (train)5.4s: train loss = 0.03092 = (mf)0.02596 + (embed)0.00497\n",
      "Epoch 38 (train)5.4s: train loss = 0.03037 = (mf)0.02534 + (embed)0.00503\n",
      "Epoch 39 (train)5.6s: train loss = 0.03008 = (mf)0.02500 + (embed)0.00508\n",
      "Epoch 40 (train)5.1s + (eval)0.3s: train loss = 0.03124 = (mf)0.02611 + (embed)0.00513, recall = 0.14485, ndcg = 0.28999, precision = 0.24557, map = 0.08399\n",
      "Epoch 41 (train)5.2s: train loss = 0.02941 = (mf)0.02422 + (embed)0.00519\n",
      "Epoch 42 (train)5.3s: train loss = 0.02985 = (mf)0.02459 + (embed)0.00525\n",
      "Epoch 43 (train)5.2s: train loss = 0.02935 = (mf)0.02407 + (embed)0.00529\n",
      "Epoch 44 (train)5.4s: train loss = 0.02841 = (mf)0.02305 + (embed)0.00536\n",
      "Epoch 45 (train)5.0s + (eval)0.2s: train loss = 0.02847 = (mf)0.02309 + (embed)0.00538, recall = 0.14274, ndcg = 0.28957, precision = 0.24672, map = 0.08135\n",
      "Epoch 46 (train)5.2s: train loss = 0.02889 = (mf)0.02348 + (embed)0.00541\n",
      "Epoch 47 (train)5.0s: train loss = 0.02823 = (mf)0.02279 + (embed)0.00545\n",
      "Epoch 48 (train)4.9s: train loss = 0.02829 = (mf)0.02280 + (embed)0.00549\n",
      "Epoch 49 (train)5.0s: train loss = 0.02851 = (mf)0.02299 + (embed)0.00552\n",
      "Epoch 50 (train)5.0s + (eval)0.2s: train loss = 0.02705 = (mf)0.02148 + (embed)0.00557, recall = 0.14140, ndcg = 0.28874, precision = 0.24393, map = 0.08327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80762b48dd3a4cc08c21347d33ac5f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▃▂▃▁▂▆▂▂</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▄▇███▇▇▇▇</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▄▇▇█▇▇▇▇▇</td></tr><tr><td>precision</td><td>▁▄▇▇██▇▆▆▆</td></tr><tr><td>recall</td><td>▁▄▇▇██▇█▇▇</td></tr><tr><td>train_time</td><td>▄▂▁▃▂▂▃▂▁▂▁▂▂▂▁▂▂▂▁▁▄▃▃▂▃▃▂▃▄▆▆█▄▅▅▆▄▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00557</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.23442</td></tr><tr><td>loss</td><td>0.02705</td></tr><tr><td>map</td><td>0.08327</td></tr><tr><td>mf_loss</td><td>0.02148</td></tr><tr><td>ndcg</td><td>0.28874</td></tr><tr><td>precision</td><td>0.24393</td></tr><tr><td>recall</td><td>0.1414</td></tr><tr><td>train_time</td><td>5.01229</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR1_1.7912694364187152_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2s8g9yp4\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2s8g9yp4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_115345-2s8g9yp4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc17c7665779487a93f43577cd77796d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0171999999981684, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_115813-1hfgcjtr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1hfgcjtr\" target=\"_blank\">experiment_AmpBPR2_1.7912694364187152_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.47706 = (mf)0.47678 + (embed)0.00028\n",
      "Epoch 2 (train)4.9s: train loss = 0.29883 = (mf)0.29811 + (embed)0.00073\n",
      "Epoch 3 (train)4.9s: train loss = 0.26672 = (mf)0.26576 + (embed)0.00096\n",
      "Epoch 4 (train)5.0s: train loss = 0.24814 = (mf)0.24699 + (embed)0.00115\n",
      "Epoch 5 (train)4.9s + (eval)0.4s: train loss = 0.23155 = (mf)0.23022 + (embed)0.00133, recall = 0.12201, ndcg = 0.25582, precision = 0.22000, map = 0.06790\n",
      "Epoch 6 (train)5.0s: train loss = 0.21879 = (mf)0.21729 + (embed)0.00149\n",
      "Epoch 7 (train)4.9s: train loss = 0.20925 = (mf)0.20758 + (embed)0.00167\n",
      "Epoch 8 (train)5.1s: train loss = 0.19730 = (mf)0.19545 + (embed)0.00184\n",
      "Epoch 9 (train)5.1s: train loss = 0.18507 = (mf)0.18302 + (embed)0.00204\n",
      "Epoch 10 (train)4.9s + (eval)0.2s: train loss = 0.17645 = (mf)0.17422 + (embed)0.00223, recall = 0.13707, ndcg = 0.28673, precision = 0.24377, map = 0.08228\n",
      "Epoch 11 (train)5.1s: train loss = 0.16671 = (mf)0.16427 + (embed)0.00244\n",
      "Epoch 12 (train)5.2s: train loss = 0.16293 = (mf)0.16031 + (embed)0.00262\n",
      "Epoch 13 (train)5.3s: train loss = 0.15581 = (mf)0.15298 + (embed)0.00283\n",
      "Epoch 14 (train)5.0s: train loss = 0.14754 = (mf)0.14449 + (embed)0.00304\n",
      "Epoch 15 (train)5.1s + (eval)0.2s: train loss = 0.14127 = (mf)0.13804 + (embed)0.00323, recall = 0.14405, ndcg = 0.30196, precision = 0.26000, map = 0.08528\n",
      "Epoch 16 (train)5.0s: train loss = 0.13969 = (mf)0.13627 + (embed)0.00342\n",
      "Epoch 17 (train)4.9s: train loss = 0.13324 = (mf)0.12964 + (embed)0.00361\n",
      "Epoch 18 (train)4.9s: train loss = 0.12968 = (mf)0.12589 + (embed)0.00379\n",
      "Epoch 19 (train)5.2s: train loss = 0.12867 = (mf)0.12468 + (embed)0.00399\n",
      "Epoch 20 (train)5.4s + (eval)0.3s: train loss = 0.12078 = (mf)0.11660 + (embed)0.00418, recall = 0.15532, ndcg = 0.31869, precision = 0.27295, map = 0.09206\n",
      "Epoch 21 (train)5.3s: train loss = 0.11931 = (mf)0.11497 + (embed)0.00434\n",
      "Epoch 22 (train)5.3s: train loss = 0.11618 = (mf)0.11166 + (embed)0.00452\n",
      "Epoch 23 (train)4.9s: train loss = 0.11332 = (mf)0.10862 + (embed)0.00470\n",
      "Epoch 24 (train)5.0s: train loss = 0.11233 = (mf)0.10748 + (embed)0.00484\n",
      "Epoch 25 (train)5.0s + (eval)0.3s: train loss = 0.10813 = (mf)0.10310 + (embed)0.00502, recall = 0.15473, ndcg = 0.31813, precision = 0.27361, map = 0.09280\n",
      "Epoch 26 (train)4.9s: train loss = 0.10850 = (mf)0.10332 + (embed)0.00517\n",
      "Epoch 27 (train)4.9s: train loss = 0.10675 = (mf)0.10145 + (embed)0.00530\n",
      "Epoch 28 (train)4.9s: train loss = 0.10386 = (mf)0.09843 + (embed)0.00543\n",
      "Epoch 29 (train)5.0s: train loss = 0.10413 = (mf)0.09855 + (embed)0.00558\n",
      "Epoch 30 (train)4.9s + (eval)0.2s: train loss = 0.10026 = (mf)0.09454 + (embed)0.00571, recall = 0.15402, ndcg = 0.31705, precision = 0.27098, map = 0.09246\n",
      "Epoch 31 (train)4.9s: train loss = 0.10106 = (mf)0.09520 + (embed)0.00586\n",
      "Epoch 32 (train)5.0s: train loss = 0.10095 = (mf)0.09496 + (embed)0.00598\n",
      "Epoch 33 (train)4.9s: train loss = 0.09626 = (mf)0.09014 + (embed)0.00613\n",
      "Epoch 34 (train)4.9s: train loss = 0.09841 = (mf)0.09218 + (embed)0.00623\n",
      "Epoch 35 (train)5.0s + (eval)0.2s: train loss = 0.09680 = (mf)0.09047 + (embed)0.00633, recall = 0.15448, ndcg = 0.31972, precision = 0.27164, map = 0.09375\n",
      "Epoch 36 (train)5.0s: train loss = 0.09456 = (mf)0.08813 + (embed)0.00643\n",
      "Epoch 37 (train)4.9s: train loss = 0.09398 = (mf)0.08743 + (embed)0.00655\n",
      "Epoch 38 (train)5.0s: train loss = 0.09540 = (mf)0.08874 + (embed)0.00666\n",
      "Epoch 39 (train)4.9s: train loss = 0.09292 = (mf)0.08615 + (embed)0.00676\n",
      "Epoch 40 (train)4.9s + (eval)0.2s: train loss = 0.09165 = (mf)0.08477 + (embed)0.00688, recall = 0.15516, ndcg = 0.32158, precision = 0.27164, map = 0.09487\n",
      "Epoch 41 (train)4.9s: train loss = 0.09041 = (mf)0.08342 + (embed)0.00698\n",
      "Epoch 42 (train)4.9s: train loss = 0.09174 = (mf)0.08468 + (embed)0.00706\n",
      "Epoch 43 (train)4.9s: train loss = 0.08856 = (mf)0.08140 + (embed)0.00716\n",
      "Epoch 44 (train)4.9s: train loss = 0.09008 = (mf)0.08283 + (embed)0.00725\n",
      "Epoch 45 (train)4.9s + (eval)0.2s: train loss = 0.08734 = (mf)0.07999 + (embed)0.00735, recall = 0.15700, ndcg = 0.32043, precision = 0.27180, map = 0.09477\n",
      "Epoch 46 (train)5.0s: train loss = 0.09019 = (mf)0.08277 + (embed)0.00741\n",
      "Epoch 47 (train)4.9s: train loss = 0.08894 = (mf)0.08142 + (embed)0.00752\n",
      "Epoch 48 (train)4.9s: train loss = 0.08923 = (mf)0.08163 + (embed)0.00759\n",
      "Epoch 49 (train)4.9s: train loss = 0.08722 = (mf)0.07955 + (embed)0.00766\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.08641 = (mf)0.07864 + (embed)0.00777, recall = 0.15546, ndcg = 0.31615, precision = 0.26852, map = 0.09220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▂▆▄▂▂▂▂▂</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▅▆▇▇▇███▇</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▄▆██████▇</td></tr><tr><td>precision</td><td>▁▄▆██████▇</td></tr><tr><td>recall</td><td>▁▄▅██▇▇███</td></tr><tr><td>train_time</td><td>▅▂▁▄▃▂▅▅▅▆█▃▃▂▁▅█▇▂▃▂▂▂▃▂▃▂▂▂▂▂▂▁▁▁▂▃▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00777</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.23434</td></tr><tr><td>loss</td><td>0.08641</td></tr><tr><td>map</td><td>0.0922</td></tr><tr><td>mf_loss</td><td>0.07864</td></tr><tr><td>ndcg</td><td>0.31615</td></tr><tr><td>precision</td><td>0.26852</td></tr><tr><td>recall</td><td>0.15546</td></tr><tr><td>train_time</td><td>4.86453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR2_1.7912694364187152_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1hfgcjtr\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1hfgcjtr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_115813-1hfgcjtr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\fyp1\\lib\\site-packages\\recommenders\\models\\deeprec\\DataModel\\ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_120242-1qo6cugn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1qo6cugn\" target=\"_blank\">experiment_OriginalBPR_1.5606823473502276_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.36136 = (mf)0.36100 + (embed)0.00037\n",
      "Epoch 2 (train)4.9s: train loss = 0.20250 = (mf)0.20174 + (embed)0.00076\n",
      "Epoch 3 (train)5.1s: train loss = 0.17491 = (mf)0.17396 + (embed)0.00095\n",
      "Epoch 4 (train)5.5s: train loss = 0.15844 = (mf)0.15728 + (embed)0.00116\n",
      "Epoch 5 (train)5.1s + (eval)0.4s: train loss = 0.14247 = (mf)0.14109 + (embed)0.00138, recall = 0.10084, ndcg = 0.21711, precision = 0.19279, map = 0.05185\n",
      "Epoch 6 (train)4.9s: train loss = 0.13379 = (mf)0.13220 + (embed)0.00159\n",
      "Epoch 7 (train)4.9s: train loss = 0.12451 = (mf)0.12273 + (embed)0.00177\n",
      "Epoch 8 (train)4.9s: train loss = 0.11503 = (mf)0.11305 + (embed)0.00198\n",
      "Epoch 9 (train)4.9s: train loss = 0.11124 = (mf)0.10905 + (embed)0.00219\n",
      "Epoch 10 (train)5.0s + (eval)0.3s: train loss = 0.10190 = (mf)0.09950 + (embed)0.00241, recall = 0.10281, ndcg = 0.22387, precision = 0.19787, map = 0.05395\n",
      "Epoch 11 (train)5.0s: train loss = 0.09770 = (mf)0.09507 + (embed)0.00263\n",
      "Epoch 12 (train)5.0s: train loss = 0.09133 = (mf)0.08848 + (embed)0.00284\n",
      "Epoch 13 (train)4.9s: train loss = 0.08826 = (mf)0.08519 + (embed)0.00307\n",
      "Epoch 14 (train)4.9s: train loss = 0.08325 = (mf)0.07998 + (embed)0.00327\n",
      "Epoch 15 (train)4.9s + (eval)0.2s: train loss = 0.07675 = (mf)0.07325 + (embed)0.00350, recall = 0.11772, ndcg = 0.25327, precision = 0.22115, map = 0.06349\n",
      "Epoch 16 (train)5.2s: train loss = 0.07336 = (mf)0.06964 + (embed)0.00371\n",
      "Epoch 17 (train)5.0s: train loss = 0.07411 = (mf)0.07021 + (embed)0.00390\n",
      "Epoch 18 (train)5.0s: train loss = 0.06935 = (mf)0.06527 + (embed)0.00408\n",
      "Epoch 19 (train)4.9s: train loss = 0.06387 = (mf)0.05957 + (embed)0.00430\n",
      "Epoch 20 (train)5.0s + (eval)0.2s: train loss = 0.06319 = (mf)0.05870 + (embed)0.00449, recall = 0.13075, ndcg = 0.26749, precision = 0.23754, map = 0.06724\n",
      "Epoch 21 (train)5.0s: train loss = 0.06059 = (mf)0.05591 + (embed)0.00468\n",
      "Epoch 22 (train)4.9s: train loss = 0.05875 = (mf)0.05390 + (embed)0.00484\n",
      "Epoch 23 (train)4.9s: train loss = 0.05587 = (mf)0.05085 + (embed)0.00501\n",
      "Epoch 24 (train)5.1s: train loss = 0.05550 = (mf)0.05032 + (embed)0.00518\n",
      "Epoch 25 (train)5.0s + (eval)0.2s: train loss = 0.05376 = (mf)0.04843 + (embed)0.00533, recall = 0.13380, ndcg = 0.27687, precision = 0.24246, map = 0.07392\n",
      "Epoch 26 (train)5.0s: train loss = 0.05349 = (mf)0.04802 + (embed)0.00547\n",
      "Epoch 27 (train)5.1s: train loss = 0.04998 = (mf)0.04435 + (embed)0.00563\n",
      "Epoch 28 (train)5.1s: train loss = 0.05004 = (mf)0.04427 + (embed)0.00577\n",
      "Epoch 29 (train)5.1s: train loss = 0.04867 = (mf)0.04277 + (embed)0.00589\n",
      "Epoch 30 (train)4.9s + (eval)0.2s: train loss = 0.04689 = (mf)0.04087 + (embed)0.00603, recall = 0.13318, ndcg = 0.27031, precision = 0.23967, map = 0.07226\n",
      "Epoch 31 (train)4.9s: train loss = 0.04682 = (mf)0.04067 + (embed)0.00614\n",
      "Epoch 32 (train)5.0s: train loss = 0.04629 = (mf)0.04003 + (embed)0.00627\n",
      "Epoch 33 (train)5.3s: train loss = 0.04400 = (mf)0.03760 + (embed)0.00639\n",
      "Epoch 34 (train)5.2s: train loss = 0.04270 = (mf)0.03622 + (embed)0.00649\n",
      "Epoch 35 (train)5.0s + (eval)0.2s: train loss = 0.04308 = (mf)0.03647 + (embed)0.00661, recall = 0.13984, ndcg = 0.27864, precision = 0.24639, map = 0.07468\n",
      "Epoch 36 (train)5.0s: train loss = 0.04217 = (mf)0.03547 + (embed)0.00670\n",
      "Epoch 37 (train)4.9s: train loss = 0.04122 = (mf)0.03442 + (embed)0.00680\n",
      "Epoch 38 (train)4.9s: train loss = 0.04071 = (mf)0.03383 + (embed)0.00687\n",
      "Epoch 39 (train)5.0s: train loss = 0.04048 = (mf)0.03352 + (embed)0.00696\n",
      "Epoch 40 (train)5.2s + (eval)0.3s: train loss = 0.03957 = (mf)0.03250 + (embed)0.00707, recall = 0.13926, ndcg = 0.28042, precision = 0.24918, map = 0.07523\n",
      "Epoch 41 (train)5.1s: train loss = 0.03774 = (mf)0.03060 + (embed)0.00715\n",
      "Epoch 42 (train)5.0s: train loss = 0.03868 = (mf)0.03143 + (embed)0.00725\n",
      "Epoch 43 (train)4.9s: train loss = 0.03784 = (mf)0.03053 + (embed)0.00731\n",
      "Epoch 44 (train)4.9s: train loss = 0.03686 = (mf)0.02948 + (embed)0.00738\n",
      "Epoch 45 (train)4.9s + (eval)0.2s: train loss = 0.03725 = (mf)0.02982 + (embed)0.00743, recall = 0.13965, ndcg = 0.27804, precision = 0.24607, map = 0.07447\n",
      "Epoch 46 (train)4.9s: train loss = 0.03659 = (mf)0.02908 + (embed)0.00751\n",
      "Epoch 47 (train)4.9s: train loss = 0.03603 = (mf)0.02846 + (embed)0.00757\n",
      "Epoch 48 (train)4.9s: train loss = 0.03447 = (mf)0.02683 + (embed)0.00763\n",
      "Epoch 49 (train)4.9s: train loss = 0.03587 = (mf)0.02817 + (embed)0.00770\n",
      "Epoch 50 (train)5.1s + (eval)0.2s: train loss = 0.03488 = (mf)0.02714 + (embed)0.00774, recall = 0.14061, ndcg = 0.28212, precision = 0.24525, map = 0.07570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c703c37d5d458997e3271cfda1f076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▁▁▁▂▁▃▁▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▂▄▆▇▇████</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▂▅▆▇▇████</td></tr><tr><td>precision</td><td>▁▂▅▇▇▇████</td></tr><tr><td>recall</td><td>▁▁▄▆▇▇████</td></tr><tr><td>train_time</td><td>▅▁▃█▁▁▁▁▃▂▂▁▄▂▃▁▃▁▁▄▂▄▄▄▂▃▆▅▂▁▂▃▄▂▁▂▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00774</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.2297</td></tr><tr><td>loss</td><td>0.03488</td></tr><tr><td>map</td><td>0.0757</td></tr><tr><td>mf_loss</td><td>0.02714</td></tr><tr><td>ndcg</td><td>0.28212</td></tr><tr><td>precision</td><td>0.24525</td></tr><tr><td>recall</td><td>0.14061</td></tr><tr><td>train_time</td><td>5.07234</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_OriginalBPR_1.5606823473502276_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1qo6cugn\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/1qo6cugn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_120242-1qo6cugn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95912e77d13844b488816ebe2eae1ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_120708-3n44q7az</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/3n44q7az\" target=\"_blank\">experiment_AmpBPR1_1.5606823473502276_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.33714 = (mf)0.33685 + (embed)0.00029\n",
      "Epoch 2 (train)5.1s: train loss = 0.20606 = (mf)0.20555 + (embed)0.00050\n",
      "Epoch 3 (train)5.0s: train loss = 0.17896 = (mf)0.17830 + (embed)0.00066\n",
      "Epoch 4 (train)5.0s: train loss = 0.15271 = (mf)0.15186 + (embed)0.00085\n",
      "Epoch 5 (train)5.1s + (eval)0.4s: train loss = 0.13499 = (mf)0.13393 + (embed)0.00106, recall = 0.08946, ndcg = 0.20495, precision = 0.18000, map = 0.04701\n",
      "Epoch 6 (train)5.1s: train loss = 0.12541 = (mf)0.12417 + (embed)0.00123\n",
      "Epoch 7 (train)5.1s: train loss = 0.11114 = (mf)0.10972 + (embed)0.00142\n",
      "Epoch 8 (train)5.1s: train loss = 0.10388 = (mf)0.10230 + (embed)0.00159\n",
      "Epoch 9 (train)5.3s: train loss = 0.09739 = (mf)0.09562 + (embed)0.00177\n",
      "Epoch 10 (train)5.1s + (eval)0.2s: train loss = 0.09007 = (mf)0.08812 + (embed)0.00195, recall = 0.10154, ndcg = 0.22336, precision = 0.19787, map = 0.05051\n",
      "Epoch 11 (train)5.1s: train loss = 0.08186 = (mf)0.07971 + (embed)0.00214\n",
      "Epoch 12 (train)5.2s: train loss = 0.07635 = (mf)0.07401 + (embed)0.00234\n",
      "Epoch 13 (train)5.0s: train loss = 0.07231 = (mf)0.06979 + (embed)0.00251\n",
      "Epoch 14 (train)5.1s: train loss = 0.06727 = (mf)0.06458 + (embed)0.00269\n",
      "Epoch 15 (train)5.2s + (eval)0.2s: train loss = 0.06377 = (mf)0.06090 + (embed)0.00287, recall = 0.11489, ndcg = 0.24506, precision = 0.21672, map = 0.05831\n",
      "Epoch 16 (train)5.0s: train loss = 0.05994 = (mf)0.05688 + (embed)0.00306\n",
      "Epoch 17 (train)4.9s: train loss = 0.05702 = (mf)0.05380 + (embed)0.00322\n",
      "Epoch 18 (train)4.9s: train loss = 0.05569 = (mf)0.05232 + (embed)0.00337\n",
      "Epoch 19 (train)4.9s: train loss = 0.05281 = (mf)0.04929 + (embed)0.00352\n",
      "Epoch 20 (train)4.9s + (eval)0.2s: train loss = 0.05016 = (mf)0.04650 + (embed)0.00366, recall = 0.13334, ndcg = 0.26898, precision = 0.23984, map = 0.06968\n",
      "Epoch 21 (train)4.9s: train loss = 0.04924 = (mf)0.04545 + (embed)0.00379\n",
      "Epoch 22 (train)4.9s: train loss = 0.04761 = (mf)0.04369 + (embed)0.00393\n",
      "Epoch 23 (train)4.9s: train loss = 0.04674 = (mf)0.04270 + (embed)0.00404\n",
      "Epoch 24 (train)4.9s: train loss = 0.04577 = (mf)0.04162 + (embed)0.00416\n",
      "Epoch 25 (train)4.9s + (eval)0.2s: train loss = 0.04226 = (mf)0.03799 + (embed)0.00427, recall = 0.13753, ndcg = 0.27684, precision = 0.24033, map = 0.07463\n",
      "Epoch 26 (train)4.9s: train loss = 0.04167 = (mf)0.03727 + (embed)0.00440\n",
      "Epoch 27 (train)4.9s: train loss = 0.04112 = (mf)0.03662 + (embed)0.00450\n",
      "Epoch 28 (train)4.9s: train loss = 0.03903 = (mf)0.03444 + (embed)0.00459\n",
      "Epoch 29 (train)4.9s: train loss = 0.04004 = (mf)0.03536 + (embed)0.00468\n",
      "Epoch 30 (train)5.1s + (eval)0.2s: train loss = 0.03903 = (mf)0.03425 + (embed)0.00478, recall = 0.13250, ndcg = 0.27200, precision = 0.24049, map = 0.07182\n",
      "Epoch 31 (train)5.1s: train loss = 0.03821 = (mf)0.03334 + (embed)0.00486\n",
      "Epoch 32 (train)4.9s: train loss = 0.03673 = (mf)0.03178 + (embed)0.00495\n",
      "Epoch 33 (train)5.0s: train loss = 0.03620 = (mf)0.03116 + (embed)0.00503\n",
      "Epoch 34 (train)5.0s: train loss = 0.03599 = (mf)0.03088 + (embed)0.00511\n",
      "Epoch 35 (train)5.2s + (eval)0.2s: train loss = 0.03630 = (mf)0.03111 + (embed)0.00519, recall = 0.13764, ndcg = 0.27515, precision = 0.24689, map = 0.07440\n",
      "Epoch 36 (train)4.9s: train loss = 0.03462 = (mf)0.02934 + (embed)0.00528\n",
      "Epoch 37 (train)5.0s: train loss = 0.03390 = (mf)0.02856 + (embed)0.00535\n",
      "Epoch 38 (train)5.1s: train loss = 0.03339 = (mf)0.02798 + (embed)0.00541\n",
      "Epoch 39 (train)5.1s: train loss = 0.03229 = (mf)0.02684 + (embed)0.00545\n",
      "Epoch 40 (train)5.0s + (eval)0.3s: train loss = 0.03117 = (mf)0.02565 + (embed)0.00552, recall = 0.13476, ndcg = 0.27667, precision = 0.24197, map = 0.07415\n",
      "Epoch 41 (train)5.0s: train loss = 0.03291 = (mf)0.02733 + (embed)0.00558\n",
      "Epoch 42 (train)5.0s: train loss = 0.03270 = (mf)0.02706 + (embed)0.00564\n",
      "Epoch 43 (train)5.0s: train loss = 0.03058 = (mf)0.02491 + (embed)0.00568\n",
      "Epoch 44 (train)5.3s: train loss = 0.03102 = (mf)0.02526 + (embed)0.00576\n",
      "Epoch 45 (train)6.2s + (eval)0.3s: train loss = 0.02988 = (mf)0.02409 + (embed)0.00579, recall = 0.13307, ndcg = 0.27588, precision = 0.24246, map = 0.07251\n",
      "Epoch 46 (train)5.0s: train loss = 0.03040 = (mf)0.02456 + (embed)0.00583\n",
      "Epoch 47 (train)4.9s: train loss = 0.03079 = (mf)0.02490 + (embed)0.00588\n",
      "Epoch 48 (train)5.0s: train loss = 0.03058 = (mf)0.02465 + (embed)0.00593\n",
      "Epoch 49 (train)5.0s: train loss = 0.02999 = (mf)0.02402 + (embed)0.00597\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.03034 = (mf)0.02433 + (embed)0.00600, recall = 0.13960, ndcg = 0.27969, precision = 0.24393, map = 0.07567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5183dac814824f24b7c641da3f816a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▁▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▂▂▁▂▂▂▆▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▂▄▇█▇██▇█</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▃▅▇█▇████</td></tr><tr><td>precision</td><td>▁▃▅▇▇▇█▇██</td></tr><tr><td>recall</td><td>▁▃▅▇█▇█▇▇█</td></tr><tr><td>train_time</td><td>▆▄▃▃▄▄▄█▅▆▃▄▃▂▁▁▂▂▁▁▁▂▂▂▅▂▃▃▂▃▄▅▃▃▃█▄▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.006</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.22841</td></tr><tr><td>loss</td><td>0.03034</td></tr><tr><td>map</td><td>0.07567</td></tr><tr><td>mf_loss</td><td>0.02433</td></tr><tr><td>ndcg</td><td>0.27969</td></tr><tr><td>precision</td><td>0.24393</td></tr><tr><td>recall</td><td>0.1396</td></tr><tr><td>train_time</td><td>4.94264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR1_1.5606823473502276_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/3n44q7az\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/3n44q7az</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_120708-3n44q7az\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c658df27140e4c8c9c03c671b389678e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333336530875, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_121138-mbwfgw1y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/mbwfgw1y\" target=\"_blank\">experiment_AmpBPR2_1.5606823473502276_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.8s: train loss = 0.45286 = (mf)0.45256 + (embed)0.00030\n",
      "Epoch 2 (train)6.4s: train loss = 0.27866 = (mf)0.27795 + (embed)0.00071\n",
      "Epoch 3 (train)6.2s: train loss = 0.24071 = (mf)0.23975 + (embed)0.00095\n",
      "Epoch 4 (train)5.4s: train loss = 0.22174 = (mf)0.22059 + (embed)0.00115\n",
      "Epoch 5 (train)5.3s + (eval)0.4s: train loss = 0.21025 = (mf)0.20893 + (embed)0.00132, recall = 0.09748, ndcg = 0.21951, precision = 0.19328, map = 0.05046\n",
      "Epoch 6 (train)5.3s: train loss = 0.19959 = (mf)0.19811 + (embed)0.00148\n",
      "Epoch 7 (train)5.4s: train loss = 0.18679 = (mf)0.18514 + (embed)0.00165\n",
      "Epoch 8 (train)5.5s: train loss = 0.18216 = (mf)0.18034 + (embed)0.00182\n",
      "Epoch 9 (train)5.1s: train loss = 0.16990 = (mf)0.16790 + (embed)0.00199\n",
      "Epoch 10 (train)5.1s + (eval)0.2s: train loss = 0.15704 = (mf)0.15485 + (embed)0.00219, recall = 0.11351, ndcg = 0.24525, precision = 0.21344, map = 0.06078\n",
      "Epoch 11 (train)5.0s: train loss = 0.15296 = (mf)0.15055 + (embed)0.00240\n",
      "Epoch 12 (train)5.0s: train loss = 0.14562 = (mf)0.14302 + (embed)0.00259\n",
      "Epoch 13 (train)5.1s: train loss = 0.13616 = (mf)0.13336 + (embed)0.00281\n",
      "Epoch 14 (train)5.1s: train loss = 0.13121 = (mf)0.12819 + (embed)0.00302\n",
      "Epoch 15 (train)5.0s + (eval)0.2s: train loss = 0.12738 = (mf)0.12416 + (embed)0.00323, recall = 0.12842, ndcg = 0.26672, precision = 0.23213, map = 0.07165\n",
      "Epoch 16 (train)5.0s: train loss = 0.12040 = (mf)0.11698 + (embed)0.00341\n",
      "Epoch 17 (train)5.8s: train loss = 0.11500 = (mf)0.11137 + (embed)0.00363\n",
      "Epoch 18 (train)5.7s: train loss = 0.11440 = (mf)0.11059 + (embed)0.00381\n",
      "Epoch 19 (train)5.2s: train loss = 0.10764 = (mf)0.10363 + (embed)0.00401\n",
      "Epoch 20 (train)5.1s + (eval)0.2s: train loss = 0.10589 = (mf)0.10169 + (embed)0.00420, recall = 0.13340, ndcg = 0.27983, precision = 0.24459, map = 0.07471\n",
      "Epoch 21 (train)4.9s: train loss = 0.10165 = (mf)0.09725 + (embed)0.00439\n",
      "Epoch 22 (train)5.1s: train loss = 0.09911 = (mf)0.09456 + (embed)0.00456\n",
      "Epoch 23 (train)5.0s: train loss = 0.09666 = (mf)0.09192 + (embed)0.00474\n",
      "Epoch 24 (train)4.9s: train loss = 0.09545 = (mf)0.09056 + (embed)0.00489\n",
      "Epoch 25 (train)4.9s + (eval)0.3s: train loss = 0.09372 = (mf)0.08867 + (embed)0.00505, recall = 0.13523, ndcg = 0.28136, precision = 0.24590, map = 0.07491\n",
      "Epoch 26 (train)5.0s: train loss = 0.09193 = (mf)0.08672 + (embed)0.00521\n",
      "Epoch 27 (train)5.1s: train loss = 0.08929 = (mf)0.08393 + (embed)0.00536\n",
      "Epoch 28 (train)5.1s: train loss = 0.08785 = (mf)0.08236 + (embed)0.00549\n",
      "Epoch 29 (train)5.1s: train loss = 0.08537 = (mf)0.07973 + (embed)0.00565\n",
      "Epoch 30 (train)5.0s + (eval)0.2s: train loss = 0.08568 = (mf)0.07990 + (embed)0.00578, recall = 0.13815, ndcg = 0.28674, precision = 0.25000, map = 0.07828\n",
      "Epoch 31 (train)5.0s: train loss = 0.08086 = (mf)0.07496 + (embed)0.00590\n",
      "Epoch 32 (train)5.0s: train loss = 0.08049 = (mf)0.07445 + (embed)0.00604\n",
      "Epoch 33 (train)4.9s: train loss = 0.08165 = (mf)0.07547 + (embed)0.00618\n",
      "Epoch 34 (train)5.0s: train loss = 0.07999 = (mf)0.07369 + (embed)0.00630\n",
      "Epoch 35 (train)5.1s + (eval)0.2s: train loss = 0.07948 = (mf)0.07306 + (embed)0.00642, recall = 0.13943, ndcg = 0.28726, precision = 0.25262, map = 0.07662\n",
      "Epoch 36 (train)5.1s: train loss = 0.07558 = (mf)0.06906 + (embed)0.00652\n",
      "Epoch 37 (train)4.9s: train loss = 0.07681 = (mf)0.07017 + (embed)0.00664\n",
      "Epoch 38 (train)4.9s: train loss = 0.07448 = (mf)0.06774 + (embed)0.00674\n",
      "Epoch 39 (train)5.0s: train loss = 0.07822 = (mf)0.07136 + (embed)0.00686\n",
      "Epoch 40 (train)4.9s + (eval)0.3s: train loss = 0.07380 = (mf)0.06684 + (embed)0.00696, recall = 0.13844, ndcg = 0.28600, precision = 0.24902, map = 0.07557\n",
      "Epoch 41 (train)5.2s: train loss = 0.07295 = (mf)0.06588 + (embed)0.00707\n",
      "Epoch 42 (train)4.9s: train loss = 0.07264 = (mf)0.06547 + (embed)0.00717\n",
      "Epoch 43 (train)4.9s: train loss = 0.07307 = (mf)0.06581 + (embed)0.00726\n",
      "Epoch 44 (train)5.0s: train loss = 0.07221 = (mf)0.06485 + (embed)0.00736\n",
      "Epoch 45 (train)5.0s + (eval)0.3s: train loss = 0.07106 = (mf)0.06362 + (embed)0.00744, recall = 0.13741, ndcg = 0.28942, precision = 0.24885, map = 0.07804\n",
      "Epoch 46 (train)4.9s: train loss = 0.07222 = (mf)0.06469 + (embed)0.00754\n",
      "Epoch 47 (train)4.9s: train loss = 0.07151 = (mf)0.06391 + (embed)0.00760\n",
      "Epoch 48 (train)4.9s: train loss = 0.07192 = (mf)0.06423 + (embed)0.00768\n",
      "Epoch 49 (train)4.9s: train loss = 0.06848 = (mf)0.06071 + (embed)0.00777\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.07029 = (mf)0.06245 + (embed)0.00784, recall = 0.13409, ndcg = 0.28808, precision = 0.24738, map = 0.07782\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0162ad2f7848b4b5a7e39af16229e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▂▂▂▁▁▂▂▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▄▆▇▇██▇██</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▄▆▇▇█████</td></tr><tr><td>precision</td><td>▁▃▆▇▇████▇</td></tr><tr><td>recall</td><td>▁▄▆▇▇████▇</td></tr><tr><td>train_time</td><td>▅█▇▃▃▃▄▂▁▂▂▂▂▅▅▂▁▂▂▁▂▂▂▂▁▁▁▂▂▁▁▂▂▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00784</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.23721</td></tr><tr><td>loss</td><td>0.07029</td></tr><tr><td>map</td><td>0.07782</td></tr><tr><td>mf_loss</td><td>0.06245</td></tr><tr><td>ndcg</td><td>0.28808</td></tr><tr><td>precision</td><td>0.24738</td></tr><tr><td>recall</td><td>0.13409</td></tr><tr><td>train_time</td><td>4.91203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR2_1.5606823473502276_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/mbwfgw1y\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/mbwfgw1y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_121138-mbwfgw1y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\fyp1\\lib\\site-packages\\recommenders\\models\\deeprec\\DataModel\\ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_121613-2gdd21uw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2gdd21uw\" target=\"_blank\">experiment_OriginalBPR_1.7672886054282924_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.36694 = (mf)0.36658 + (embed)0.00037\n",
      "Epoch 2 (train)5.0s: train loss = 0.20932 = (mf)0.20857 + (embed)0.00075\n",
      "Epoch 3 (train)5.0s: train loss = 0.18310 = (mf)0.18217 + (embed)0.00094\n",
      "Epoch 4 (train)5.1s: train loss = 0.16044 = (mf)0.15927 + (embed)0.00118\n",
      "Epoch 5 (train)5.1s + (eval)0.5s: train loss = 0.14380 = (mf)0.14237 + (embed)0.00143, recall = 0.11868, ndcg = 0.25370, precision = 0.21525, map = 0.06993\n",
      "Epoch 6 (train)5.1s: train loss = 0.13308 = (mf)0.13143 + (embed)0.00165\n",
      "Epoch 7 (train)4.9s: train loss = 0.12377 = (mf)0.12190 + (embed)0.00187\n",
      "Epoch 8 (train)4.9s: train loss = 0.11280 = (mf)0.11071 + (embed)0.00209\n",
      "Epoch 9 (train)5.0s: train loss = 0.11199 = (mf)0.10971 + (embed)0.00228\n",
      "Epoch 10 (train)5.0s + (eval)0.3s: train loss = 0.10429 = (mf)0.10182 + (embed)0.00247, recall = 0.12390, ndcg = 0.25814, precision = 0.22279, map = 0.07032\n",
      "Epoch 11 (train)5.1s: train loss = 0.09905 = (mf)0.09640 + (embed)0.00266\n",
      "Epoch 12 (train)5.0s: train loss = 0.09281 = (mf)0.08994 + (embed)0.00287\n",
      "Epoch 13 (train)5.0s: train loss = 0.08645 = (mf)0.08335 + (embed)0.00309\n",
      "Epoch 14 (train)5.2s: train loss = 0.08493 = (mf)0.08164 + (embed)0.00329\n",
      "Epoch 15 (train)5.0s + (eval)0.3s: train loss = 0.07906 = (mf)0.07555 + (embed)0.00351, recall = 0.12891, ndcg = 0.27752, precision = 0.23672, map = 0.07504\n",
      "Epoch 16 (train)5.2s: train loss = 0.07352 = (mf)0.06978 + (embed)0.00374\n",
      "Epoch 17 (train)5.2s: train loss = 0.07203 = (mf)0.06809 + (embed)0.00395\n",
      "Epoch 18 (train)4.9s: train loss = 0.06731 = (mf)0.06316 + (embed)0.00415\n",
      "Epoch 19 (train)5.1s: train loss = 0.06522 = (mf)0.06087 + (embed)0.00435\n",
      "Epoch 20 (train)5.1s + (eval)0.3s: train loss = 0.06303 = (mf)0.05847 + (embed)0.00456, recall = 0.14112, ndcg = 0.29576, precision = 0.25377, map = 0.08190\n",
      "Epoch 21 (train)5.2s: train loss = 0.06061 = (mf)0.05587 + (embed)0.00474\n",
      "Epoch 22 (train)4.9s: train loss = 0.05941 = (mf)0.05448 + (embed)0.00493\n",
      "Epoch 23 (train)5.0s: train loss = 0.05591 = (mf)0.05079 + (embed)0.00512\n",
      "Epoch 24 (train)5.1s: train loss = 0.05474 = (mf)0.04946 + (embed)0.00528\n",
      "Epoch 25 (train)5.0s + (eval)0.3s: train loss = 0.05394 = (mf)0.04848 + (embed)0.00546, recall = 0.14945, ndcg = 0.30451, precision = 0.26180, map = 0.08712\n",
      "Epoch 26 (train)5.0s: train loss = 0.05194 = (mf)0.04633 + (embed)0.00562\n",
      "Epoch 27 (train)4.9s: train loss = 0.05152 = (mf)0.04578 + (embed)0.00574\n",
      "Epoch 28 (train)5.0s: train loss = 0.04970 = (mf)0.04384 + (embed)0.00587\n",
      "Epoch 29 (train)5.1s: train loss = 0.04916 = (mf)0.04317 + (embed)0.00599\n",
      "Epoch 30 (train)4.9s + (eval)0.3s: train loss = 0.04567 = (mf)0.03953 + (embed)0.00614, recall = 0.15172, ndcg = 0.31210, precision = 0.26541, map = 0.09068\n",
      "Epoch 31 (train)4.9s: train loss = 0.04569 = (mf)0.03942 + (embed)0.00627\n",
      "Epoch 32 (train)5.1s: train loss = 0.04551 = (mf)0.03912 + (embed)0.00639\n",
      "Epoch 33 (train)5.0s: train loss = 0.04309 = (mf)0.03657 + (embed)0.00652\n",
      "Epoch 34 (train)5.2s: train loss = 0.04313 = (mf)0.03651 + (embed)0.00661\n",
      "Epoch 35 (train)5.0s + (eval)0.2s: train loss = 0.04097 = (mf)0.03423 + (embed)0.00675, recall = 0.15411, ndcg = 0.31471, precision = 0.27033, map = 0.09105\n",
      "Epoch 36 (train)5.0s: train loss = 0.04202 = (mf)0.03518 + (embed)0.00684\n",
      "Epoch 37 (train)5.0s: train loss = 0.04152 = (mf)0.03460 + (embed)0.00693\n",
      "Epoch 38 (train)5.4s: train loss = 0.03994 = (mf)0.03290 + (embed)0.00704\n",
      "Epoch 39 (train)5.2s: train loss = 0.03897 = (mf)0.03184 + (embed)0.00713\n",
      "Epoch 40 (train)5.1s + (eval)0.3s: train loss = 0.03906 = (mf)0.03184 + (embed)0.00722, recall = 0.15352, ndcg = 0.31673, precision = 0.27000, map = 0.09164\n",
      "Epoch 41 (train)5.1s: train loss = 0.03891 = (mf)0.03163 + (embed)0.00728\n",
      "Epoch 42 (train)5.1s: train loss = 0.03862 = (mf)0.03126 + (embed)0.00736\n",
      "Epoch 43 (train)5.5s: train loss = 0.03744 = (mf)0.03002 + (embed)0.00742\n",
      "Epoch 44 (train)5.4s: train loss = 0.03710 = (mf)0.02961 + (embed)0.00749\n",
      "Epoch 45 (train)5.2s + (eval)0.3s: train loss = 0.03516 = (mf)0.02760 + (embed)0.00755, recall = 0.15710, ndcg = 0.31807, precision = 0.27344, map = 0.09413\n",
      "Epoch 46 (train)5.2s: train loss = 0.03494 = (mf)0.02731 + (embed)0.00764\n",
      "Epoch 47 (train)5.1s: train loss = 0.03512 = (mf)0.02743 + (embed)0.00769\n",
      "Epoch 48 (train)5.2s: train loss = 0.03597 = (mf)0.02822 + (embed)0.00775\n",
      "Epoch 49 (train)5.5s: train loss = 0.03560 = (mf)0.02781 + (embed)0.00779\n",
      "Epoch 50 (train)5.2s + (eval)0.3s: train loss = 0.03494 = (mf)0.02711 + (embed)0.00784, recall = 0.15249, ndcg = 0.31421, precision = 0.26852, map = 0.09162\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f71900941141e3bc7b93a69a1af108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▂▂▂▂▁▂▂▂</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▁▂▄▆▇▇▇█▇</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▁▄▆▇▇████</td></tr><tr><td>precision</td><td>▁▂▄▆▇▇███▇</td></tr><tr><td>recall</td><td>▁▂▃▅▇▇▇▇█▇</td></tr><tr><td>train_time</td><td>▅▂▂▄▃▁▁▃▄▃▂▅▅▄▁▃▅▁▃▃▂▂▃▃▁▃▃▅▂▂▇▅▃▄█▇▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00784</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.26754</td></tr><tr><td>loss</td><td>0.03494</td></tr><tr><td>map</td><td>0.09162</td></tr><tr><td>mf_loss</td><td>0.02711</td></tr><tr><td>ndcg</td><td>0.31421</td></tr><tr><td>precision</td><td>0.26852</td></tr><tr><td>recall</td><td>0.15249</td></tr><tr><td>train_time</td><td>5.16627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_OriginalBPR_1.7672886054282924_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2gdd21uw\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2gdd21uw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_121613-2gdd21uw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f6a499f10042b6901476b99a5e6abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_122041-94c98rvy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/94c98rvy\" target=\"_blank\">experiment_AmpBPR1_1.7672886054282924_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.4s: train loss = 0.32969 = (mf)0.32941 + (embed)0.00028\n",
      "Epoch 2 (train)4.9s: train loss = 0.16341 = (mf)0.16283 + (embed)0.00058\n",
      "Epoch 3 (train)5.1s: train loss = 0.13997 = (mf)0.13920 + (embed)0.00077\n",
      "Epoch 4 (train)5.2s: train loss = 0.13047 = (mf)0.12956 + (embed)0.00091\n",
      "Epoch 5 (train)5.1s + (eval)0.5s: train loss = 0.11865 = (mf)0.11759 + (embed)0.00106, recall = 0.11942, ndcg = 0.25070, precision = 0.21639, map = 0.07004\n",
      "Epoch 6 (train)5.3s: train loss = 0.10984 = (mf)0.10864 + (embed)0.00120\n",
      "Epoch 7 (train)5.3s: train loss = 0.10264 = (mf)0.10131 + (embed)0.00134\n",
      "Epoch 8 (train)5.0s: train loss = 0.09561 = (mf)0.09413 + (embed)0.00148\n",
      "Epoch 9 (train)4.9s: train loss = 0.08885 = (mf)0.08721 + (embed)0.00164\n",
      "Epoch 10 (train)5.0s + (eval)0.3s: train loss = 0.08320 = (mf)0.08141 + (embed)0.00179, recall = 0.12106, ndcg = 0.26244, precision = 0.22918, map = 0.06900\n",
      "Epoch 11 (train)5.3s: train loss = 0.07618 = (mf)0.07422 + (embed)0.00195\n",
      "Epoch 12 (train)5.4s: train loss = 0.07158 = (mf)0.06947 + (embed)0.00212\n",
      "Epoch 13 (train)5.7s: train loss = 0.06940 = (mf)0.06712 + (embed)0.00228\n",
      "Epoch 14 (train)5.4s: train loss = 0.06576 = (mf)0.06332 + (embed)0.00244\n",
      "Epoch 15 (train)5.1s + (eval)0.3s: train loss = 0.06261 = (mf)0.06002 + (embed)0.00259, recall = 0.13639, ndcg = 0.28717, precision = 0.24852, map = 0.07824\n",
      "Epoch 16 (train)5.2s: train loss = 0.05851 = (mf)0.05578 + (embed)0.00274\n",
      "Epoch 17 (train)5.0s: train loss = 0.05594 = (mf)0.05305 + (embed)0.00289\n",
      "Epoch 18 (train)5.1s: train loss = 0.05174 = (mf)0.04870 + (embed)0.00303\n",
      "Epoch 19 (train)5.2s: train loss = 0.05004 = (mf)0.04687 + (embed)0.00318\n",
      "Epoch 20 (train)5.6s + (eval)0.4s: train loss = 0.04822 = (mf)0.04492 + (embed)0.00330, recall = 0.14247, ndcg = 0.29571, precision = 0.25639, map = 0.08070\n",
      "Epoch 21 (train)6.7s: train loss = 0.04760 = (mf)0.04418 + (embed)0.00342\n",
      "Epoch 22 (train)5.5s: train loss = 0.04541 = (mf)0.04186 + (embed)0.00355\n",
      "Epoch 23 (train)5.7s: train loss = 0.04503 = (mf)0.04136 + (embed)0.00367\n",
      "Epoch 24 (train)5.2s: train loss = 0.04334 = (mf)0.03956 + (embed)0.00378\n",
      "Epoch 25 (train)5.2s + (eval)0.2s: train loss = 0.03945 = (mf)0.03555 + (embed)0.00390, recall = 0.14841, ndcg = 0.30583, precision = 0.26344, map = 0.08554\n",
      "Epoch 26 (train)5.0s: train loss = 0.04085 = (mf)0.03685 + (embed)0.00400\n",
      "Epoch 27 (train)5.1s: train loss = 0.03969 = (mf)0.03560 + (embed)0.00409\n",
      "Epoch 28 (train)5.0s: train loss = 0.03752 = (mf)0.03332 + (embed)0.00420\n",
      "Epoch 29 (train)4.9s: train loss = 0.03705 = (mf)0.03276 + (embed)0.00429\n",
      "Epoch 30 (train)5.2s + (eval)0.2s: train loss = 0.03751 = (mf)0.03313 + (embed)0.00438, recall = 0.14409, ndcg = 0.29564, precision = 0.25443, map = 0.08178\n",
      "Epoch 31 (train)5.3s: train loss = 0.03542 = (mf)0.03097 + (embed)0.00446\n",
      "Epoch 32 (train)5.6s: train loss = 0.03487 = (mf)0.03034 + (embed)0.00454\n",
      "Epoch 33 (train)5.6s: train loss = 0.03375 = (mf)0.02914 + (embed)0.00462\n",
      "Epoch 34 (train)5.1s: train loss = 0.03408 = (mf)0.02938 + (embed)0.00470\n",
      "Epoch 35 (train)5.0s + (eval)0.3s: train loss = 0.03453 = (mf)0.02977 + (embed)0.00476, recall = 0.14897, ndcg = 0.29819, precision = 0.26115, map = 0.08330\n",
      "Epoch 36 (train)5.3s: train loss = 0.03368 = (mf)0.02885 + (embed)0.00484\n",
      "Epoch 37 (train)5.0s: train loss = 0.03245 = (mf)0.02753 + (embed)0.00492\n",
      "Epoch 38 (train)5.0s: train loss = 0.03216 = (mf)0.02720 + (embed)0.00497\n",
      "Epoch 39 (train)4.9s: train loss = 0.03245 = (mf)0.02744 + (embed)0.00501\n",
      "Epoch 40 (train)4.9s + (eval)0.3s: train loss = 0.03171 = (mf)0.02663 + (embed)0.00508, recall = 0.14899, ndcg = 0.29676, precision = 0.25656, map = 0.08419\n",
      "Epoch 41 (train)4.9s: train loss = 0.03123 = (mf)0.02610 + (embed)0.00513\n",
      "Epoch 42 (train)5.1s: train loss = 0.02999 = (mf)0.02480 + (embed)0.00519\n",
      "Epoch 43 (train)5.3s: train loss = 0.03042 = (mf)0.02518 + (embed)0.00523\n",
      "Epoch 44 (train)5.0s: train loss = 0.02881 = (mf)0.02351 + (embed)0.00531\n",
      "Epoch 45 (train)5.1s + (eval)0.3s: train loss = 0.02982 = (mf)0.02449 + (embed)0.00534, recall = 0.14686, ndcg = 0.29703, precision = 0.25508, map = 0.08404\n",
      "Epoch 46 (train)5.2s: train loss = 0.02866 = (mf)0.02328 + (embed)0.00538\n",
      "Epoch 47 (train)4.9s: train loss = 0.02829 = (mf)0.02285 + (embed)0.00544\n",
      "Epoch 48 (train)5.1s: train loss = 0.02825 = (mf)0.02278 + (embed)0.00547\n",
      "Epoch 49 (train)4.9s: train loss = 0.02868 = (mf)0.02317 + (embed)0.00551\n",
      "Epoch 50 (train)4.9s + (eval)0.3s: train loss = 0.02734 = (mf)0.02179 + (embed)0.00556, recall = 0.14886, ndcg = 0.29442, precision = 0.25377, map = 0.08388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▂█▁▁▂▂▂▂</td></tr><tr><td>loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▁▅▆█▆▇▇▇▇</td></tr><tr><td>mf_loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▂▆▇█▇▇▇▇▇</td></tr><tr><td>precision</td><td>▁▃▆▇█▇█▇▇▇</td></tr><tr><td>recall</td><td>▁▁▅▆█▇██▇█</td></tr><tr><td>train_time</td><td>▃▁▂▂▂▃▂▁▃▃▄▃▂▂▂▂█▄▄▂▁▂▁▁▂▄▄▂▂▂▂▁▁▂▃▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00556</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.26406</td></tr><tr><td>loss</td><td>0.02734</td></tr><tr><td>map</td><td>0.08388</td></tr><tr><td>mf_loss</td><td>0.02179</td></tr><tr><td>ndcg</td><td>0.29442</td></tr><tr><td>precision</td><td>0.25377</td></tr><tr><td>recall</td><td>0.14886</td></tr><tr><td>train_time</td><td>4.94478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR1_1.7672886054282924_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/94c98rvy\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/94c98rvy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_122041-94c98rvy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae063bc356b48e89d278b28fd4167da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_122524-37poq2q5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/37poq2q5\" target=\"_blank\">experiment_AmpBPR2_1.7672886054282924_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.8s: train loss = 0.48016 = (mf)0.47989 + (embed)0.00027\n",
      "Epoch 2 (train)5.2s: train loss = 0.32694 = (mf)0.32631 + (embed)0.00064\n",
      "Epoch 3 (train)5.0s: train loss = 0.28098 = (mf)0.28011 + (embed)0.00087\n",
      "Epoch 4 (train)5.0s: train loss = 0.26020 = (mf)0.25912 + (embed)0.00107\n",
      "Epoch 5 (train)4.9s + (eval)0.4s: train loss = 0.23571 = (mf)0.23445 + (embed)0.00125, recall = 0.12713, ndcg = 0.25542, precision = 0.22393, map = 0.06956\n",
      "Epoch 6 (train)5.0s: train loss = 0.22212 = (mf)0.22068 + (embed)0.00144\n",
      "Epoch 7 (train)4.9s: train loss = 0.20649 = (mf)0.20485 + (embed)0.00163\n",
      "Epoch 8 (train)5.0s: train loss = 0.19766 = (mf)0.19583 + (embed)0.00182\n",
      "Epoch 9 (train)5.0s: train loss = 0.18478 = (mf)0.18276 + (embed)0.00202\n",
      "Epoch 10 (train)5.0s + (eval)0.2s: train loss = 0.17700 = (mf)0.17480 + (embed)0.00221, recall = 0.13371, ndcg = 0.28502, precision = 0.24361, map = 0.07979\n",
      "Epoch 11 (train)4.9s: train loss = 0.17115 = (mf)0.16874 + (embed)0.00240\n",
      "Epoch 12 (train)5.1s: train loss = 0.16171 = (mf)0.15912 + (embed)0.00259\n",
      "Epoch 13 (train)5.2s: train loss = 0.15603 = (mf)0.15324 + (embed)0.00279\n",
      "Epoch 14 (train)5.0s: train loss = 0.14525 = (mf)0.14224 + (embed)0.00301\n",
      "Epoch 15 (train)5.0s + (eval)0.2s: train loss = 0.14141 = (mf)0.13821 + (embed)0.00319, recall = 0.14227, ndcg = 0.29875, precision = 0.25705, map = 0.08428\n",
      "Epoch 16 (train)5.0s: train loss = 0.13665 = (mf)0.13326 + (embed)0.00339\n",
      "Epoch 17 (train)5.0s: train loss = 0.13264 = (mf)0.12906 + (embed)0.00357\n",
      "Epoch 18 (train)5.0s: train loss = 0.12925 = (mf)0.12551 + (embed)0.00374\n",
      "Epoch 19 (train)5.0s: train loss = 0.12605 = (mf)0.12214 + (embed)0.00391\n",
      "Epoch 20 (train)5.1s + (eval)0.2s: train loss = 0.12314 = (mf)0.11905 + (embed)0.00408, recall = 0.14867, ndcg = 0.31182, precision = 0.27016, map = 0.08890\n",
      "Epoch 21 (train)5.0s: train loss = 0.11867 = (mf)0.11442 + (embed)0.00425\n",
      "Epoch 22 (train)5.0s: train loss = 0.11971 = (mf)0.11530 + (embed)0.00441\n",
      "Epoch 23 (train)5.0s: train loss = 0.11433 = (mf)0.10976 + (embed)0.00457\n",
      "Epoch 24 (train)5.0s: train loss = 0.11043 = (mf)0.10571 + (embed)0.00472\n",
      "Epoch 25 (train)4.9s + (eval)0.2s: train loss = 0.11220 = (mf)0.10733 + (embed)0.00487, recall = 0.15850, ndcg = 0.31898, precision = 0.27623, map = 0.09313\n",
      "Epoch 26 (train)4.9s: train loss = 0.10488 = (mf)0.09985 + (embed)0.00503\n",
      "Epoch 27 (train)4.9s: train loss = 0.10536 = (mf)0.10019 + (embed)0.00518\n",
      "Epoch 28 (train)4.9s: train loss = 0.10793 = (mf)0.10264 + (embed)0.00529\n",
      "Epoch 29 (train)4.9s: train loss = 0.10412 = (mf)0.09869 + (embed)0.00542\n",
      "Epoch 30 (train)5.0s + (eval)0.2s: train loss = 0.10171 = (mf)0.09616 + (embed)0.00555, recall = 0.15897, ndcg = 0.32326, precision = 0.27721, map = 0.09580\n",
      "Epoch 31 (train)4.9s: train loss = 0.10178 = (mf)0.09611 + (embed)0.00566\n",
      "Epoch 32 (train)4.9s: train loss = 0.09873 = (mf)0.09294 + (embed)0.00580\n",
      "Epoch 33 (train)4.9s: train loss = 0.09960 = (mf)0.09368 + (embed)0.00592\n",
      "Epoch 34 (train)4.9s: train loss = 0.09516 = (mf)0.08914 + (embed)0.00602\n",
      "Epoch 35 (train)4.9s + (eval)0.3s: train loss = 0.09632 = (mf)0.09018 + (embed)0.00615, recall = 0.15824, ndcg = 0.31796, precision = 0.27377, map = 0.09279\n",
      "Epoch 36 (train)4.9s: train loss = 0.09311 = (mf)0.08685 + (embed)0.00627\n",
      "Epoch 37 (train)4.9s: train loss = 0.09489 = (mf)0.08852 + (embed)0.00637\n",
      "Epoch 38 (train)4.9s: train loss = 0.09226 = (mf)0.08579 + (embed)0.00648\n",
      "Epoch 39 (train)4.9s: train loss = 0.09211 = (mf)0.08551 + (embed)0.00661\n",
      "Epoch 40 (train)4.9s + (eval)0.3s: train loss = 0.09087 = (mf)0.08418 + (embed)0.00669, recall = 0.15854, ndcg = 0.32218, precision = 0.27902, map = 0.09338\n",
      "Epoch 41 (train)4.9s: train loss = 0.09077 = (mf)0.08398 + (embed)0.00679\n",
      "Epoch 42 (train)4.9s: train loss = 0.08887 = (mf)0.08195 + (embed)0.00691\n",
      "Epoch 43 (train)4.9s: train loss = 0.08746 = (mf)0.08048 + (embed)0.00698\n",
      "Epoch 44 (train)4.9s: train loss = 0.08654 = (mf)0.07945 + (embed)0.00709\n",
      "Epoch 45 (train)4.9s + (eval)0.3s: train loss = 0.08820 = (mf)0.08100 + (embed)0.00719, recall = 0.16219, ndcg = 0.32535, precision = 0.27820, map = 0.09697\n",
      "Epoch 46 (train)4.9s: train loss = 0.08682 = (mf)0.07954 + (embed)0.00727\n",
      "Epoch 47 (train)4.9s: train loss = 0.08763 = (mf)0.08027 + (embed)0.00736\n",
      "Epoch 48 (train)4.9s: train loss = 0.08653 = (mf)0.07909 + (embed)0.00744\n",
      "Epoch 49 (train)4.9s: train loss = 0.08687 = (mf)0.07934 + (embed)0.00754\n",
      "Epoch 50 (train)4.9s + (eval)0.3s: train loss = 0.08834 = (mf)0.08074 + (embed)0.00760, recall = 0.16242, ndcg = 0.32808, precision = 0.27902, map = 0.09811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▁▁▁▁▂▂▂▂</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>mf_loss</td><td>█▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▄▅▆▇█▇▇██</td></tr><tr><td>precision</td><td>▁▃▅▇██▇███</td></tr><tr><td>recall</td><td>▁▂▄▅▇▇▇▇██</td></tr><tr><td>train_time</td><td>█▄▂▂▂▁▂▂▁▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.0076</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.25004</td></tr><tr><td>loss</td><td>0.08834</td></tr><tr><td>map</td><td>0.09811</td></tr><tr><td>mf_loss</td><td>0.08074</td></tr><tr><td>ndcg</td><td>0.32808</td></tr><tr><td>precision</td><td>0.27902</td></tr><tr><td>recall</td><td>0.16242</td></tr><tr><td>train_time</td><td>4.87616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR2_1.7672886054282924_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/37poq2q5\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/37poq2q5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_122524-37poq2q5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanch\\anaconda3\\envs\\fyp1\\lib\\site-packages\\recommenders\\models\\deeprec\\DataModel\\ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_122952-3m9ll3vf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/3m9ll3vf\" target=\"_blank\">experiment_OriginalBPR_1.5302548366951503_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.36573 = (mf)0.36537 + (embed)0.00036\n",
      "Epoch 2 (train)4.9s: train loss = 0.20443 = (mf)0.20368 + (embed)0.00076\n",
      "Epoch 3 (train)4.9s: train loss = 0.17737 = (mf)0.17642 + (embed)0.00095\n",
      "Epoch 4 (train)4.9s: train loss = 0.15309 = (mf)0.15189 + (embed)0.00120\n",
      "Epoch 5 (train)4.9s + (eval)0.4s: train loss = 0.13639 = (mf)0.13494 + (embed)0.00145, recall = 0.10966, ndcg = 0.23859, precision = 0.20525, map = 0.06127\n",
      "Epoch 6 (train)4.9s: train loss = 0.12396 = (mf)0.12227 + (embed)0.00169\n",
      "Epoch 7 (train)5.6s: train loss = 0.11793 = (mf)0.11604 + (embed)0.00189\n",
      "Epoch 8 (train)5.2s: train loss = 0.11172 = (mf)0.10965 + (embed)0.00207\n",
      "Epoch 9 (train)5.1s: train loss = 0.10864 = (mf)0.10640 + (embed)0.00225\n",
      "Epoch 10 (train)5.7s + (eval)0.2s: train loss = 0.10248 = (mf)0.10007 + (embed)0.00241, recall = 0.11491, ndcg = 0.24727, precision = 0.20967, map = 0.06828\n",
      "Epoch 11 (train)5.1s: train loss = 0.09829 = (mf)0.09570 + (embed)0.00259\n",
      "Epoch 12 (train)5.3s: train loss = 0.09512 = (mf)0.09237 + (embed)0.00275\n",
      "Epoch 13 (train)5.0s: train loss = 0.08753 = (mf)0.08459 + (embed)0.00295\n",
      "Epoch 14 (train)4.9s: train loss = 0.08392 = (mf)0.08078 + (embed)0.00314\n",
      "Epoch 15 (train)4.9s + (eval)0.2s: train loss = 0.07967 = (mf)0.07632 + (embed)0.00335, recall = 0.11827, ndcg = 0.25661, precision = 0.21984, map = 0.06633\n",
      "Epoch 16 (train)4.9s: train loss = 0.07690 = (mf)0.07334 + (embed)0.00356\n",
      "Epoch 17 (train)4.9s: train loss = 0.07407 = (mf)0.07030 + (embed)0.00377\n",
      "Epoch 18 (train)4.9s: train loss = 0.06939 = (mf)0.06543 + (embed)0.00396\n",
      "Epoch 19 (train)4.9s: train loss = 0.06781 = (mf)0.06364 + (embed)0.00417\n",
      "Epoch 20 (train)5.0s + (eval)0.2s: train loss = 0.06188 = (mf)0.05751 + (embed)0.00437, recall = 0.13312, ndcg = 0.28451, precision = 0.24508, map = 0.07700\n",
      "Epoch 21 (train)4.9s: train loss = 0.05910 = (mf)0.05454 + (embed)0.00456\n",
      "Epoch 22 (train)5.0s: train loss = 0.06035 = (mf)0.05562 + (embed)0.00473\n",
      "Epoch 23 (train)5.0s: train loss = 0.05800 = (mf)0.05307 + (embed)0.00492\n",
      "Epoch 24 (train)5.1s: train loss = 0.05522 = (mf)0.05012 + (embed)0.00511\n",
      "Epoch 25 (train)5.0s + (eval)0.2s: train loss = 0.05282 = (mf)0.04756 + (embed)0.00526, recall = 0.14288, ndcg = 0.29109, precision = 0.25082, map = 0.08155\n",
      "Epoch 26 (train)5.0s: train loss = 0.05181 = (mf)0.04640 + (embed)0.00541\n",
      "Epoch 27 (train)5.0s: train loss = 0.05114 = (mf)0.04556 + (embed)0.00558\n",
      "Epoch 28 (train)4.9s: train loss = 0.04889 = (mf)0.04317 + (embed)0.00572\n",
      "Epoch 29 (train)5.1s: train loss = 0.04830 = (mf)0.04244 + (embed)0.00586\n",
      "Epoch 30 (train)5.0s + (eval)0.2s: train loss = 0.04637 = (mf)0.04039 + (embed)0.00598, recall = 0.14525, ndcg = 0.29340, precision = 0.25393, map = 0.08145\n",
      "Epoch 31 (train)4.9s: train loss = 0.04627 = (mf)0.04015 + (embed)0.00612\n",
      "Epoch 32 (train)5.0s: train loss = 0.04476 = (mf)0.03851 + (embed)0.00625\n",
      "Epoch 33 (train)4.9s: train loss = 0.04373 = (mf)0.03735 + (embed)0.00638\n",
      "Epoch 34 (train)4.9s: train loss = 0.04288 = (mf)0.03640 + (embed)0.00648\n",
      "Epoch 35 (train)4.9s + (eval)0.2s: train loss = 0.04326 = (mf)0.03668 + (embed)0.00658, recall = 0.14655, ndcg = 0.29801, precision = 0.25869, map = 0.08368\n",
      "Epoch 36 (train)5.0s: train loss = 0.04176 = (mf)0.03507 + (embed)0.00669\n",
      "Epoch 37 (train)4.9s: train loss = 0.04078 = (mf)0.03397 + (embed)0.00681\n",
      "Epoch 38 (train)4.9s: train loss = 0.03889 = (mf)0.03199 + (embed)0.00690\n",
      "Epoch 39 (train)4.9s: train loss = 0.03933 = (mf)0.03233 + (embed)0.00700\n",
      "Epoch 40 (train)4.9s + (eval)0.3s: train loss = 0.03908 = (mf)0.03200 + (embed)0.00707, recall = 0.15089, ndcg = 0.30574, precision = 0.25967, map = 0.08895\n",
      "Epoch 41 (train)4.9s: train loss = 0.03727 = (mf)0.03012 + (embed)0.00715\n",
      "Epoch 42 (train)4.9s: train loss = 0.03872 = (mf)0.03149 + (embed)0.00723\n",
      "Epoch 43 (train)4.9s: train loss = 0.03673 = (mf)0.02943 + (embed)0.00730\n",
      "Epoch 44 (train)4.9s: train loss = 0.03630 = (mf)0.02894 + (embed)0.00737\n",
      "Epoch 45 (train)4.9s + (eval)0.2s: train loss = 0.03654 = (mf)0.02911 + (embed)0.00744, recall = 0.14848, ndcg = 0.29686, precision = 0.25787, map = 0.08365\n",
      "Epoch 46 (train)5.0s: train loss = 0.03635 = (mf)0.02884 + (embed)0.00752\n",
      "Epoch 47 (train)4.9s: train loss = 0.03556 = (mf)0.02800 + (embed)0.00756\n",
      "Epoch 48 (train)5.0s: train loss = 0.03535 = (mf)0.02772 + (embed)0.00763\n",
      "Epoch 49 (train)4.9s: train loss = 0.03531 = (mf)0.02764 + (embed)0.00768\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.03329 = (mf)0.02555 + (embed)0.00774, recall = 0.14731, ndcg = 0.29775, precision = 0.25459, map = 0.08543\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▂▁▁▁▁▁▂▁▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▃▂▅▆▆▇█▇▇</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▂▃▆▆▇▇█▇▇</td></tr><tr><td>precision</td><td>▁▂▃▆▇▇███▇</td></tr><tr><td>recall</td><td>▁▂▂▅▇▇▇██▇</td></tr><tr><td>train_time</td><td>▄▁▁▁▁█▄▃▃▅▂▁▁▁▁▁▂▂▂▃▂▃▁▃▁▂▁▂▂▁▁▂▁▁▂▁▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00774</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.24172</td></tr><tr><td>loss</td><td>0.03329</td></tr><tr><td>map</td><td>0.08543</td></tr><tr><td>mf_loss</td><td>0.02555</td></tr><tr><td>ndcg</td><td>0.29775</td></tr><tr><td>precision</td><td>0.25459</td></tr><tr><td>recall</td><td>0.14731</td></tr><tr><td>train_time</td><td>4.94494</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_OriginalBPR_1.5302548366951503_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/3m9ll3vf\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/3m9ll3vf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_122952-3m9ll3vf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d65be71f6f4eb182d82f110dc42f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_123419-2pw7w2jt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2pw7w2jt\" target=\"_blank\">experiment_AmpBPR1_1.5302548366951503_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.2s: train loss = 0.34020 = (mf)0.33991 + (embed)0.00029\n",
      "Epoch 2 (train)4.9s: train loss = 0.19286 = (mf)0.19230 + (embed)0.00055\n",
      "Epoch 3 (train)4.9s: train loss = 0.15823 = (mf)0.15748 + (embed)0.00075\n",
      "Epoch 4 (train)4.9s: train loss = 0.14228 = (mf)0.14135 + (embed)0.00094\n",
      "Epoch 5 (train)5.2s + (eval)0.5s: train loss = 0.12981 = (mf)0.12870 + (embed)0.00111, recall = 0.10827, ndcg = 0.23348, precision = 0.19934, map = 0.06150\n",
      "Epoch 6 (train)5.2s: train loss = 0.11843 = (mf)0.11715 + (embed)0.00128\n",
      "Epoch 7 (train)6.0s: train loss = 0.11254 = (mf)0.11111 + (embed)0.00144\n",
      "Epoch 8 (train)6.2s: train loss = 0.10202 = (mf)0.10040 + (embed)0.00162\n",
      "Epoch 9 (train)5.3s: train loss = 0.09410 = (mf)0.09230 + (embed)0.00180\n",
      "Epoch 10 (train)5.0s + (eval)0.2s: train loss = 0.08644 = (mf)0.08446 + (embed)0.00198, recall = 0.11777, ndcg = 0.25442, precision = 0.21738, map = 0.06687\n",
      "Epoch 11 (train)5.0s: train loss = 0.08200 = (mf)0.07982 + (embed)0.00217\n",
      "Epoch 12 (train)4.9s: train loss = 0.07512 = (mf)0.07277 + (embed)0.00235\n",
      "Epoch 13 (train)4.9s: train loss = 0.07336 = (mf)0.07082 + (embed)0.00253\n",
      "Epoch 14 (train)5.0s: train loss = 0.06750 = (mf)0.06480 + (embed)0.00270\n",
      "Epoch 15 (train)5.0s + (eval)0.3s: train loss = 0.06306 = (mf)0.06018 + (embed)0.00288, recall = 0.13513, ndcg = 0.27508, precision = 0.23869, map = 0.07508\n",
      "Epoch 16 (train)5.0s: train loss = 0.06272 = (mf)0.05967 + (embed)0.00306\n",
      "Epoch 17 (train)5.0s: train loss = 0.05927 = (mf)0.05606 + (embed)0.00321\n",
      "Epoch 18 (train)5.0s: train loss = 0.05818 = (mf)0.05484 + (embed)0.00335\n",
      "Epoch 19 (train)5.0s: train loss = 0.05378 = (mf)0.05029 + (embed)0.00349\n",
      "Epoch 20 (train)5.0s + (eval)0.3s: train loss = 0.05272 = (mf)0.04908 + (embed)0.00364, recall = 0.14314, ndcg = 0.29386, precision = 0.25016, map = 0.08357\n",
      "Epoch 21 (train)5.0s: train loss = 0.05006 = (mf)0.04628 + (embed)0.00378\n",
      "Epoch 22 (train)5.0s: train loss = 0.04906 = (mf)0.04515 + (embed)0.00391\n",
      "Epoch 23 (train)5.2s: train loss = 0.04871 = (mf)0.04468 + (embed)0.00403\n",
      "Epoch 24 (train)5.1s: train loss = 0.04450 = (mf)0.04034 + (embed)0.00416\n",
      "Epoch 25 (train)5.0s + (eval)0.2s: train loss = 0.04340 = (mf)0.03912 + (embed)0.00428, recall = 0.14320, ndcg = 0.29102, precision = 0.24803, map = 0.08260\n",
      "Epoch 26 (train)5.0s: train loss = 0.04304 = (mf)0.03863 + (embed)0.00440\n",
      "Epoch 27 (train)4.9s: train loss = 0.04127 = (mf)0.03678 + (embed)0.00449\n",
      "Epoch 28 (train)5.0s: train loss = 0.04144 = (mf)0.03682 + (embed)0.00462\n",
      "Epoch 29 (train)5.0s: train loss = 0.03952 = (mf)0.03481 + (embed)0.00471\n",
      "Epoch 30 (train)5.0s + (eval)0.2s: train loss = 0.03911 = (mf)0.03430 + (embed)0.00481, recall = 0.14295, ndcg = 0.29248, precision = 0.24869, map = 0.08269\n",
      "Epoch 31 (train)5.0s: train loss = 0.03751 = (mf)0.03263 + (embed)0.00488\n",
      "Epoch 32 (train)5.1s: train loss = 0.03724 = (mf)0.03226 + (embed)0.00498\n",
      "Epoch 33 (train)5.0s: train loss = 0.03728 = (mf)0.03222 + (embed)0.00507\n",
      "Epoch 34 (train)4.9s: train loss = 0.03614 = (mf)0.03101 + (embed)0.00513\n",
      "Epoch 35 (train)5.0s + (eval)0.2s: train loss = 0.03561 = (mf)0.03039 + (embed)0.00522, recall = 0.14191, ndcg = 0.29044, precision = 0.24639, map = 0.08215\n",
      "Epoch 36 (train)5.0s: train loss = 0.03532 = (mf)0.03002 + (embed)0.00530\n",
      "Epoch 37 (train)5.0s: train loss = 0.03439 = (mf)0.02902 + (embed)0.00537\n",
      "Epoch 38 (train)5.0s: train loss = 0.03321 = (mf)0.02777 + (embed)0.00544\n",
      "Epoch 39 (train)5.0s: train loss = 0.03368 = (mf)0.02818 + (embed)0.00549\n",
      "Epoch 40 (train)5.0s + (eval)0.2s: train loss = 0.03374 = (mf)0.02818 + (embed)0.00556, recall = 0.14319, ndcg = 0.29335, precision = 0.24459, map = 0.08554\n",
      "Epoch 41 (train)5.0s: train loss = 0.03273 = (mf)0.02712 + (embed)0.00561\n",
      "Epoch 42 (train)5.0s: train loss = 0.03223 = (mf)0.02656 + (embed)0.00567\n",
      "Epoch 43 (train)5.0s: train loss = 0.03148 = (mf)0.02575 + (embed)0.00573\n",
      "Epoch 44 (train)5.0s: train loss = 0.03080 = (mf)0.02499 + (embed)0.00581\n",
      "Epoch 45 (train)4.9s + (eval)0.2s: train loss = 0.03078 = (mf)0.02495 + (embed)0.00583, recall = 0.14638, ndcg = 0.29529, precision = 0.24803, map = 0.08526\n",
      "Epoch 46 (train)5.0s: train loss = 0.03041 = (mf)0.02452 + (embed)0.00589\n",
      "Epoch 47 (train)5.0s: train loss = 0.03065 = (mf)0.02470 + (embed)0.00594\n",
      "Epoch 48 (train)5.0s: train loss = 0.02979 = (mf)0.02380 + (embed)0.00599\n",
      "Epoch 49 (train)5.0s: train loss = 0.03039 = (mf)0.02436 + (embed)0.00603\n",
      "Epoch 50 (train)4.9s + (eval)0.2s: train loss = 0.02914 = (mf)0.02308 + (embed)0.00607, recall = 0.14398, ndcg = 0.28830, precision = 0.24311, map = 0.08451\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6595f6eb81184c01b945d5743401208b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▃▅▇▇▇▇███</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▃▆███▇██▇</td></tr><tr><td>precision</td><td>▁▃▆███▇▇█▇</td></tr><tr><td>recall</td><td>▁▃▆▇▇▇▇▇██</td></tr><tr><td>train_time</td><td>▃▁▁▁▃▇█▄▂▁▁▂▁▂▂▂▁▁▃▂▂▁▁▂▂▂▂▁▂▁▁▂▂▂▁▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00607</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.23433</td></tr><tr><td>loss</td><td>0.02914</td></tr><tr><td>map</td><td>0.08451</td></tr><tr><td>mf_loss</td><td>0.02308</td></tr><tr><td>ndcg</td><td>0.2883</td></tr><tr><td>precision</td><td>0.24311</td></tr><tr><td>recall</td><td>0.14398</td></tr><tr><td>train_time</td><td>4.92964</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR1_1.5302548366951503_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2pw7w2jt\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/2pw7w2jt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_123419-2pw7w2jt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d839e973b648c3bafa0e31984db3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\tanch\\Documents\\NTU\\NTU Year 4\\FYP - GNN\\code1\\wandb\\run-20221202_123847-29ea1ns9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/29ea1ns9\" target=\"_blank\">experiment_AmpBPR2_1.5302548366951503_0.0</a></strong> to <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n",
      "Epoch 1 (train)5.3s: train loss = 0.45070 = (mf)0.45040 + (embed)0.00030\n",
      "Epoch 2 (train)5.0s: train loss = 0.27742 = (mf)0.27670 + (embed)0.00072\n",
      "Epoch 3 (train)5.0s: train loss = 0.24617 = (mf)0.24523 + (embed)0.00094\n",
      "Epoch 4 (train)5.3s: train loss = 0.22442 = (mf)0.22328 + (embed)0.00113\n",
      "Epoch 5 (train)5.4s + (eval)0.5s: train loss = 0.20977 = (mf)0.20848 + (embed)0.00129, recall = 0.11737, ndcg = 0.24296, precision = 0.20984, map = 0.06578\n",
      "Epoch 6 (train)5.2s: train loss = 0.19923 = (mf)0.19777 + (embed)0.00146\n",
      "Epoch 7 (train)5.0s: train loss = 0.18755 = (mf)0.18592 + (embed)0.00163\n",
      "Epoch 8 (train)5.0s: train loss = 0.17253 = (mf)0.17071 + (embed)0.00182\n",
      "Epoch 9 (train)5.0s: train loss = 0.16336 = (mf)0.16134 + (embed)0.00202\n",
      "Epoch 10 (train)5.0s + (eval)0.2s: train loss = 0.15664 = (mf)0.15443 + (embed)0.00221, recall = 0.13481, ndcg = 0.28050, precision = 0.23656, map = 0.07947\n",
      "Epoch 11 (train)5.0s: train loss = 0.14747 = (mf)0.14506 + (embed)0.00241\n",
      "Epoch 12 (train)5.0s: train loss = 0.14067 = (mf)0.13806 + (embed)0.00261\n",
      "Epoch 13 (train)5.1s: train loss = 0.13458 = (mf)0.13177 + (embed)0.00281\n",
      "Epoch 14 (train)5.0s: train loss = 0.12846 = (mf)0.12544 + (embed)0.00303\n",
      "Epoch 15 (train)5.0s + (eval)0.2s: train loss = 0.11986 = (mf)0.11662 + (embed)0.00323, recall = 0.14636, ndcg = 0.29263, precision = 0.25262, map = 0.08282\n",
      "Epoch 16 (train)5.0s: train loss = 0.11794 = (mf)0.11451 + (embed)0.00343\n",
      "Epoch 17 (train)5.0s: train loss = 0.11307 = (mf)0.10946 + (embed)0.00362\n",
      "Epoch 18 (train)5.0s: train loss = 0.11163 = (mf)0.10783 + (embed)0.00380\n",
      "Epoch 19 (train)5.0s: train loss = 0.10389 = (mf)0.09990 + (embed)0.00399\n",
      "Epoch 20 (train)5.0s + (eval)0.2s: train loss = 0.10203 = (mf)0.09784 + (embed)0.00418, recall = 0.15263, ndcg = 0.30523, precision = 0.26328, map = 0.08694\n",
      "Epoch 21 (train)5.0s: train loss = 0.10181 = (mf)0.09745 + (embed)0.00435\n",
      "Epoch 22 (train)5.0s: train loss = 0.09609 = (mf)0.09156 + (embed)0.00453\n",
      "Epoch 23 (train)5.0s: train loss = 0.09506 = (mf)0.09035 + (embed)0.00471\n",
      "Epoch 24 (train)5.0s: train loss = 0.09184 = (mf)0.08698 + (embed)0.00487\n",
      "Epoch 25 (train)5.0s + (eval)0.3s: train loss = 0.09176 = (mf)0.08674 + (embed)0.00502, recall = 0.15044, ndcg = 0.29917, precision = 0.25836, map = 0.08515\n",
      "Epoch 26 (train)5.0s: train loss = 0.09015 = (mf)0.08499 + (embed)0.00516\n",
      "Epoch 27 (train)5.0s: train loss = 0.08637 = (mf)0.08106 + (embed)0.00532\n",
      "Epoch 28 (train)5.0s: train loss = 0.08476 = (mf)0.07932 + (embed)0.00545\n",
      "Epoch 29 (train)5.0s: train loss = 0.08545 = (mf)0.07984 + (embed)0.00561\n",
      "Epoch 30 (train)5.0s + (eval)0.3s: train loss = 0.08135 = (mf)0.07561 + (embed)0.00574, recall = 0.15084, ndcg = 0.30061, precision = 0.25721, map = 0.08610\n",
      "Epoch 31 (train)5.0s: train loss = 0.08229 = (mf)0.07643 + (embed)0.00586\n",
      "Epoch 32 (train)5.0s: train loss = 0.08366 = (mf)0.07769 + (embed)0.00597\n",
      "Epoch 33 (train)5.0s: train loss = 0.08209 = (mf)0.07599 + (embed)0.00610\n",
      "Epoch 34 (train)4.9s: train loss = 0.08045 = (mf)0.07424 + (embed)0.00622\n",
      "Epoch 35 (train)5.0s + (eval)0.3s: train loss = 0.07596 = (mf)0.06961 + (embed)0.00635, recall = 0.15196, ndcg = 0.30048, precision = 0.25770, map = 0.08642\n",
      "Epoch 36 (train)5.0s: train loss = 0.07412 = (mf)0.06768 + (embed)0.00645\n",
      "Epoch 37 (train)5.0s: train loss = 0.07589 = (mf)0.06932 + (embed)0.00657\n",
      "Epoch 38 (train)5.0s: train loss = 0.07380 = (mf)0.06713 + (embed)0.00667\n",
      "Epoch 39 (train)5.0s: train loss = 0.07379 = (mf)0.06701 + (embed)0.00678\n",
      "Epoch 40 (train)5.0s + (eval)0.2s: train loss = 0.07408 = (mf)0.06719 + (embed)0.00688, recall = 0.15282, ndcg = 0.29848, precision = 0.25525, map = 0.08471\n",
      "Epoch 41 (train)5.0s: train loss = 0.07331 = (mf)0.06632 + (embed)0.00699\n",
      "Epoch 42 (train)5.0s: train loss = 0.07243 = (mf)0.06535 + (embed)0.00709\n",
      "Epoch 43 (train)5.0s: train loss = 0.07110 = (mf)0.06393 + (embed)0.00716\n",
      "Epoch 44 (train)5.0s: train loss = 0.07138 = (mf)0.06411 + (embed)0.00727\n",
      "Epoch 45 (train)5.0s + (eval)0.2s: train loss = 0.06901 = (mf)0.06165 + (embed)0.00736, recall = 0.15201, ndcg = 0.29926, precision = 0.25508, map = 0.08636\n",
      "Epoch 46 (train)5.0s: train loss = 0.07230 = (mf)0.06486 + (embed)0.00744\n",
      "Epoch 47 (train)5.0s: train loss = 0.06894 = (mf)0.06144 + (embed)0.00751\n",
      "Epoch 48 (train)5.0s: train loss = 0.06803 = (mf)0.06044 + (embed)0.00759\n",
      "Epoch 49 (train)5.0s: train loss = 0.07005 = (mf)0.06238 + (embed)0.00767\n",
      "Epoch 50 (train)5.0s + (eval)0.2s: train loss = 0.06799 = (mf)0.06025 + (embed)0.00774, recall = 0.15279, ndcg = 0.29679, precision = 0.25770, map = 0.08545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8f1b2049b34339b635a6eed8498752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>eval_time</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>map</td><td>▁▆▇█▇██▇██</td></tr><tr><td>mf_loss</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ndcg</td><td>▁▅▇█▇▇▇▇▇▇</td></tr><tr><td>precision</td><td>▁▅▇█▇▇▇▇▇▇</td></tr><tr><td>recall</td><td>▁▄▇███████</td></tr><tr><td>train_time</td><td>█▃▂█▅▃▂▂▁▂▄▂▂▂▂▂▂▂▁▁▂▁▁▃▂▂▂▁▂▃▂▂▂▂▂▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>emb_loss</td><td>0.00774</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>eval_time</td><td>0.24999</td></tr><tr><td>loss</td><td>0.06799</td></tr><tr><td>map</td><td>0.08545</td></tr><tr><td>mf_loss</td><td>0.06025</td></tr><tr><td>ndcg</td><td>0.29679</td></tr><tr><td>precision</td><td>0.2577</td></tr><tr><td>recall</td><td>0.15279</td></tr><tr><td>train_time</td><td>4.9863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">experiment_AmpBPR2_1.5302548366951503_0.0</strong>: <a href=\"https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/29ea1ns9\" target=\"_blank\">https://wandb.ai/chingfhen/lightgcn_loss_function_study/runs/29ea1ns9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221202_123847-29ea1ns9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed(1)\n",
    "for _ in range(n_trials):\n",
    "    \n",
    "    # sample negative item weights - new sample every trial\n",
    "    loss_neg_weight = uniform(1,2)\n",
    "    \n",
    "    # train test split - perform new split every trial \n",
    "    SEED0 = randint(0,100000)\n",
    "    train, test = python_stratified_split(df, ratio=0.8,\n",
    "                                          min_rating=1, filter_by='user', \n",
    "                                          col_user=COL_USER, col_item=COL_ITEM, \n",
    "                                          seed=SEED0)\n",
    "    data = ImplicitCF(train = train, test=test, \n",
    "                      adj_dir=None, \n",
    "                      col_user=COL_USER, col_item=COL_ITEM, \n",
    "                      seed=SEED)\n",
    "    \n",
    "    # evaluate the loss_types\n",
    "    for loss_type in loss_types: \n",
    "        # initiate parameters\n",
    "        hparams = prepare_hparams(yaml_file,\n",
    "                                  n_layers=3,\n",
    "                                  loss_type = loss_type, \n",
    "                                  loss_neg_weight = loss_neg_weight, \n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  learning_rate=0.01,\n",
    "                                  eval_epoch=5,\n",
    "                                  top_k=TOP_K,\n",
    "                                 )\n",
    "        # initiate model\n",
    "        model = LightGCN(hparams, data, seed=SEED0)\n",
    "        # train and evaluate\n",
    "        with Timer() as train_time:\n",
    "            model.fit()\n",
    "#     print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
